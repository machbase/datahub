{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoke Sensor Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "from urllib.parse import quote\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Import necessary API\n",
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "from api.v2.util.data_load import data_load\n",
    "from api.v2.model.ResNet1d import ResNet1D, ResidualBlock\n",
    "\n",
    "## Import libraries for the model\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "## Set path for saving model training results \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Set Cuda for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## Set random seed\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Set seed\n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Parameter Setting\n",
    "* Set parameters based on the information identified during EDA (Exploratory Data Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Smoke Sensor Data Parameter\n",
    "\n",
    "# Set MachBase Neo URL address\n",
    "URL = 'http://127.0.0.1:5654'\n",
    "# Set Tag Table Name\n",
    "table = 'smoke'\n",
    "# Select Tag Name -> Can Check Tag Names Using command 'show_column(URL, table)'\n",
    "# Set Austria Tag Name \n",
    "tags = ['CNT', 'Fire Alarm', 'Humidity[%]', 'PM1.0', 'Pressure[hPa]', 'Raw Ethanol', 'Raw H2', 'TVOC[ppb]', 'Temperature[C]', 'eCO2[ppm]']\n",
    "# Wrap each item in the list with single quotes and separate with commas\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "# Set Tag Name\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# Set resample Option -> D(day), H(hour), T(minute), S(second)\n",
    "resample_freq = None\n",
    "# Set Start time\n",
    "start_time = '2025-01-16 00:00:00'\n",
    "# Set End time \n",
    "end_time = '2025-01-16 17:23:49'\n",
    "# Set TimeFormat - > 'default' or quote('2006-01-02 15:04:05.000000')(Divided down to the nanosecond)\n",
    "timeformat = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoke Sensor Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke Sensor Data Load\n",
    "df = data_load(URL, table, name, start_time, end_time, timeformat, resample_freq)\n",
    "\n",
    "# Move the 'Fire Alarm' column to the last position\n",
    "df = df.reindex(columns=[col for col in df.columns if col != 'Fire Alarm'] + ['Fire Alarm'])\n",
    "\n",
    "# Convert the 'Fire Alarm' column to integer type\n",
    "df['Fire Alarm'] = df['Fire Alarm'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NAME</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>939.735</td>\n",
       "      <td>18520.0</td>\n",
       "      <td>12306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>939.744</td>\n",
       "      <td>18651.0</td>\n",
       "      <td>12345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.015</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:02</th>\n",
       "      <td>2.0</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>939.738</td>\n",
       "      <td>18764.0</td>\n",
       "      <td>12374.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.029</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:03</th>\n",
       "      <td>3.0</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>939.736</td>\n",
       "      <td>18849.0</td>\n",
       "      <td>12390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.044</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:04</th>\n",
       "      <td>4.0</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>939.744</td>\n",
       "      <td>18921.0</td>\n",
       "      <td>12403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.059</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 17:23:45</th>\n",
       "      <td>5739.0</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>936.670</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>13723.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>18.438</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 17:23:46</th>\n",
       "      <td>5740.0</td>\n",
       "      <td>15.87</td>\n",
       "      <td>0.61</td>\n",
       "      <td>936.678</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>13731.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>18.653</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 17:23:47</th>\n",
       "      <td>5741.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>936.687</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>13725.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>18.867</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 17:23:48</th>\n",
       "      <td>5742.0</td>\n",
       "      <td>16.04</td>\n",
       "      <td>0.57</td>\n",
       "      <td>936.680</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>13712.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>19.083</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 17:23:49</th>\n",
       "      <td>5743.0</td>\n",
       "      <td>16.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>936.676</td>\n",
       "      <td>20543.0</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>19.299</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62630 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NAME                    CNT  Humidity[%]  PM1.0  Pressure[hPa]  Raw Ethanol  \\\n",
       "TIME                                                                          \n",
       "2025-01-16 00:00:00     0.0        57.36   0.00        939.735      18520.0   \n",
       "2025-01-16 00:00:01     1.0        56.67   0.00        939.744      18651.0   \n",
       "2025-01-16 00:00:02     2.0        55.96   0.00        939.738      18764.0   \n",
       "2025-01-16 00:00:03     3.0        55.28   0.00        939.736      18849.0   \n",
       "2025-01-16 00:00:04     4.0        54.69   0.00        939.744      18921.0   \n",
       "...                     ...          ...    ...            ...          ...   \n",
       "2025-01-16 17:23:45  5739.0        15.79   0.63        936.670      20569.0   \n",
       "2025-01-16 17:23:46  5740.0        15.87   0.61        936.678      20588.0   \n",
       "2025-01-16 17:23:47  5741.0        15.84   0.57        936.687      20582.0   \n",
       "2025-01-16 17:23:48  5742.0        16.04   0.57        936.680      20566.0   \n",
       "2025-01-16 17:23:49  5743.0        16.52   0.57        936.676      20543.0   \n",
       "\n",
       "NAME                  Raw H2  TVOC[ppb]  Temperature[C]  eCO2[ppm]  Fire Alarm  \n",
       "TIME                                                                            \n",
       "2025-01-16 00:00:00  12306.0        0.0          20.000      400.0           0  \n",
       "2025-01-16 00:00:01  12345.0        0.0          20.015      400.0           0  \n",
       "2025-01-16 00:00:02  12374.0        0.0          20.029      400.0           0  \n",
       "2025-01-16 00:00:03  12390.0        0.0          20.044      400.0           0  \n",
       "2025-01-16 00:00:04  12403.0        0.0          20.059      400.0           0  \n",
       "...                      ...        ...             ...        ...         ...  \n",
       "2025-01-16 17:23:45  13723.0      625.0          18.438      400.0           0  \n",
       "2025-01-16 17:23:46  13731.0      612.0          18.653      400.0           0  \n",
       "2025-01-16 17:23:47  13725.0      627.0          18.867      400.0           0  \n",
       "2025-01-16 17:23:48  13712.0      638.0          19.083      400.0           0  \n",
       "2025-01-16 17:23:49  13696.0      643.0          19.299      400.0           0  \n",
       "\n",
       "[62630 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, test sets\n",
    "train = df[df.index.hour < 10]\n",
    "test = df[df.index.hour >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* 1 Min-Max Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Applying Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Scalers\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Scalers\n",
    "train_ = scaler.fit_transform(train.iloc[:,:-1].values)\n",
    "test_ = scaler.transform(test.iloc[:,:-1].values)\n",
    "\n",
    "# Set Each DataFrames\n",
    "train_scaled = pd.DataFrame(train_, columns=train.columns[:-1])\n",
    "train_scaled['Fire Alarm'] = train['Fire Alarm'].values\n",
    "  \n",
    "test_scaled = pd.DataFrame(test_, columns=test.columns[:-1])\n",
    "test_scaled['Fire Alarm'] = test['Fire Alarm'].values\n",
    "\n",
    "# Save Scaler\n",
    "with open('./result/resnet1d_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Loader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Smoke_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.freq_data = df.iloc[:,:-1]\n",
    "        self.label = df.iloc[:,-1:].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.freq_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        input_time_data = self.freq_data.iloc[index,:]\n",
    "        input_time_data = torch.Tensor(input_time_data).expand(1, input_time_data.shape[0])\n",
    "        label = self.label[index]\n",
    "\n",
    "        return input_time_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up datasets  \n",
    "train_ = Smoke_Dataset(train_scaled)\n",
    "test_ = Smoke_Dataset(test_scaled)\n",
    "\n",
    "# Set up data loaders\n",
    "train_dataloader = DataLoader(train_, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "# Verify DataLoader application and check the shape of the input data\n",
    "print(list(train_dataloader)[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "* Using ResNet1d model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1D(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model configuration parameters\n",
    " \n",
    "# Set ResidualBlock\n",
    "block = ResidualBlock\n",
    "# Set the number of ResidualBlocks to use per layer\n",
    "layers = [2,2,2,2]\n",
    "# Set the number of classification categories\n",
    "num_classes = 2\n",
    " \n",
    "# Learning rate\n",
    "lr = 0.01\n",
    " \n",
    "# Model configuration\n",
    "model = ResNet1D(block, layers, num_classes).to(device)\n",
    " \n",
    "# Configure loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    " \n",
    "# Check the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "* Save the model with the Best F1 Score based on the validation data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0991958248a435ebf7b2cefb8d1e5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.04547461824055022, train acc: 98.5944\n",
      "model save\n",
      "\n",
      "train loss: 0.014271776547288634, train acc: 99.5222\n",
      "model save\n",
      "\n",
      "train loss: 0.008839443033903485, train acc: 99.7333\n",
      "model save\n",
      "\n",
      "train loss: 0.011336452931209995, train acc: 99.6917\n",
      "\n",
      "train loss: 0.009640899327687495, train acc: 99.7000\n"
     ]
    }
   ],
   "source": [
    "# Initialize training loss\n",
    "train_loss = []\n",
    "# Initialize training accuracy\n",
    "train_acc = []\n",
    "# Initialize total step\n",
    "total_step = len(train_dataloader)\n",
    "# Set number of epochs\n",
    "epoch_in = trange(5, desc='training')\n",
    "# Initialize best F1 Score value\n",
    "best_f1= 0\n",
    "\n",
    "# Start model training\n",
    "for epoch in epoch_in:\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    preds_ = []\n",
    "    targets_ = []\n",
    "    \n",
    "    # Initialize loss\n",
    "    train_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        \n",
    "        data = data.to(device).float()\n",
    "        target = target.to(device).long().squeeze()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Input to the model\n",
    "        outputs = model(data)\n",
    "    \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Set label predictions \n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        target_ = target.view_as(pred)\n",
    "        correct += torch.sum(pred==target).item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        preds_.append(pred)\n",
    "        targets_.append(target_)\n",
    "            \n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss)}, train acc: {(100 * correct / total):.4f}')\n",
    "\n",
    "    # Combine predictions and labels collected from all batches\n",
    "    preds_ = torch.cat(preds_).detach().cpu().numpy()\n",
    "    targets_ = torch.cat(targets_).detach().cpu().numpy()\n",
    "    \n",
    "    f1score = f1_score(targets_, preds_,  average='macro')\n",
    "    if best_f1 < f1score:\n",
    "        best_f1 = f1score\n",
    "        # Save the best model \n",
    "        with open(\"./result/Smoke_Sensor_Full.txt\", \"a\") as text_file:\n",
    "            print('epoch=====',epoch, file=text_file)\n",
    "            print(classification_report(targets_, preds_, digits=4), file=text_file)\n",
    "        print('model save')\n",
    "        torch.save(model, f'./result/Smoke_Sensor_Full.pt') \n",
    "    epoch_in.set_postfix_str(f\"epoch = {epoch},  f1_score = {f1score}, best_f1 = {best_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model_ = torch.load(f'./result/Smoke_Sensor_Full.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "# Model testing\n",
    "preds_test = []\n",
    "target_test = []\n",
    "with torch.no_grad():\n",
    "    model_.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "        data = data.to(device).float()\n",
    "        target = target.to(device).long().squeeze()\n",
    "        \n",
    "        outputs_t = model_(data)\n",
    "        \n",
    "        _,pred_t = torch.max(outputs_t, dim=1)\n",
    "        targets_t = target.view_as(pred_t).to(device)\n",
    "\n",
    "        preds_test.append(pred_t)\n",
    "        target_test.append(targets_t)\n",
    "        \n",
    "    # Combine predictions and labels collected from all batches\n",
    "    preds_test = torch.cat(preds_test).detach().cpu().numpy()\n",
    "    target_test = torch.cat(target_test).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87     11517\n",
      "           1       0.88      0.93      0.90     15113\n",
      "\n",
      "    accuracy                           0.89     26630\n",
      "   macro avg       0.89      0.88      0.89     26630\n",
      "weighted avg       0.89      0.89      0.89     26630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_test, preds_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
