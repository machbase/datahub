{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driving Behavior Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "## Import necessary API\n",
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "from api.v2.util.data_load import data_load\n",
    "from api.v2.Preprocessing.Make_Time_Feature import TimeFeatureGenerator\n",
    "from api.v2.util.set_minmax import set_minmax_value\n",
    "from api.v2.Preprocessing.MinMaxScaler import MinMaxScaler\n",
    "from api.v2.model.TCN import TCN\n",
    "\n",
    "## Import libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "## Set path for saving model training results \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Set Cuda for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## Set random seed\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Set seed\n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Parameter Setting\n",
    "* Set parameters based on the information identified during EDA (Exploratory Data Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Driving Behavior Data Base Parameter\n",
    "\n",
    "# Set MachBase Neo URL address\n",
    "URL = 'http://127.0.0.1:5654'\n",
    "# Set Tag Table Name\n",
    "table = 'driving_behavior'\n",
    "# Select Tag Name -> Can Check Tag Names Using command 'show_column(URL, table)'\n",
    "tags = ['AccX', 'AccY', 'AccZ', 'Class', 'GyroX', 'GyroY', 'GyroZ']\n",
    "# Wrap each item in the list with single quotes and separate with commas\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "# Set Tag Name\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# Set resample Option -> D(day), H(hour), T(minute), S(second)\n",
    "resample_freq = None\n",
    "# Set Start time\n",
    "start_time = '2025-07-18 00:00:00'\n",
    "# Set End time \n",
    "end_time = '2025-07-18 01:52:07'\n",
    "# Set TimeFormat - > 'default' or quote('2006-01-02 15:04:05.000000')(Divided down to the nanosecond)\n",
    "timeformat = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "* Using Temporal Convolutional Network(TCN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN(\n",
      "  (network): Sequential(\n",
      "    (0): TemporalBlock(\n",
      "      (conv1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU()\n",
      "      (dropout1): Dropout(p=0.05, inplace=False)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu2): ReLU()\n",
      "      (dropout2): Dropout(p=0.05, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.05, inplace=False)\n",
      "        (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "      (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): TemporalBlock(\n",
      "      (conv1): Conv1d(32, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
      "      (relu1): ReLU()\n",
      "      (dropout1): Dropout(p=0.05, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
      "      (relu2): ReLU()\n",
      "      (dropout2): Dropout(p=0.05, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.05, inplace=False)\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "      (downsample): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model configuration parameters\n",
    "input_channels = 16\n",
    "out_channels = 3\n",
    "hidden_channels = [32, 64] \n",
    "kernel_size = 1\n",
    "dropout = 0.05\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model, loss, and optimizer\n",
    "model = TCN(num_inputs=input_channels, num_channels=hidden_channels,out_channel=out_channels, kernel_size=kernel_size, dropout=dropout).to(device)\n",
    "\n",
    "# Configure loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Loader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driving_Dataset(Dataset):\n",
    "    def __init__(self, data, target_column, seq_length=10):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Input data: Values of multiple variables over seq_length - 1\n",
    "        x = self.data[idx:idx + self.seq_length].drop(columns=[self.target_column]).values.reshape(-1, self.seq_length)  # Excluding target column\n",
    "        # Target data: Target variable value on the seq_length \n",
    "        y = self.data[self.target_column].iloc[idx + self.seq_length - 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training function\n",
    "def train(epochs, start_time_train, end_time_train, unit, Fetch_size, URL, table, name, timeformat, resample_freq, scaler, Min, Max, batch_size):\n",
    "    \n",
    "    # Initialize training loss\n",
    "    train_loss = []\n",
    "    # Initialize training accuracy\n",
    "    train_acc = []\n",
    "    \n",
    "    # Initialize best F1 Score value\n",
    "    best_f1= 0\n",
    "    \n",
    "    # Start model training\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total=0\n",
    "        preds_ = []\n",
    "        targets_ = []\n",
    "        \n",
    "        # Initialize loss and total step\n",
    "        running_loss = 0.0\n",
    "        total_step = 0\n",
    "        \n",
    "        # Set initial Time\n",
    "        args = {unit: Fetch_size}\n",
    "        start_time = start_time_train\n",
    "        end_time = str(datetime.strptime(start_time_train, \"%Y-%m-%d %H:%M:%S\") + timedelta(**args))\n",
    "        end_time_train_ = str(datetime.strptime(end_time_train, \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=1))\n",
    "        \n",
    "        # Set flag\n",
    "        flag = False\n",
    "\n",
    "        while end_time < end_time_train_:\n",
    "            \n",
    "            # Load batch data\n",
    "            data = data_load(URL, table, name, start_time, end_time, timeformat, resample_freq)\n",
    "\n",
    "            # Rename the 'Class' column to 'label'\n",
    "            data.rename(columns={'Class': 'label'}, inplace=True)\n",
    "\n",
    "            # Move the 'label' column to the last position\n",
    "            data = data.reindex(columns=[col for col in data.columns if col != 'label'] + ['label'])\n",
    "\n",
    "            # Convert the 'label' column to integer type\n",
    "            data['label'] = data['label'].astype(int)\n",
    "\n",
    "            # Apply MinMaxscaler\n",
    "            data_scaled = scaler.fit_transform(data.iloc[:,:-1].values, Min.drop(columns=[0]).values, Max.drop(columns=[0]).values)\n",
    "            \n",
    "            # Set up the DataFrame\n",
    "            data_ = pd.DataFrame(data_scaled, index=data.index)\n",
    "            data_['label'] = data['label'].values\n",
    "            \n",
    "            # Set TimeFeatureGenerator\n",
    "            feature_generator = TimeFeatureGenerator()  \n",
    "            \n",
    "            # Make Time Featrue\n",
    "            time_feature = feature_generator.generate_features(data.index)\n",
    "            \n",
    "            # concat origin dataset\n",
    "            data_ = pd.concat([data_, time_feature], axis=1)\n",
    "            \n",
    "            # Drop NaN values\n",
    "            data = data_.dropna()\n",
    "\n",
    "            # Set up dataset & Loader\n",
    "            train_ = Driving_Dataset(data, target_column='label', seq_length=2)\n",
    "\n",
    "            train_dataloader = DataLoader(train_, batch_size, shuffle=False)\n",
    "\n",
    "            # Print if the loaded data is empty\n",
    "            if len(data) != 0:\n",
    "                \n",
    "                for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "                    \n",
    "                    # Check total batch count\n",
    "                    total_step += 1\n",
    "                    \n",
    "                    data = data.to(device).float()\n",
    "                    target = target.to(device).long().squeeze()\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                    # Input to the model\n",
    "                    outputs = model(data)\n",
    "                    outputs = outputs.squeeze()\n",
    "                    \n",
    "                    # Calculate loss\n",
    "                    loss = criterion(outputs, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    \n",
    "                    # Set label predictions \n",
    "                    _,pred = torch.max(outputs, dim=1)\n",
    "                    target_ = target.view_as(pred)\n",
    "                    correct += torch.sum(pred==target).item()\n",
    "                    total += target.size(0)\n",
    "                    \n",
    "                    preds_.append(pred)\n",
    "                    targets_.append(target_)\n",
    "                    \n",
    "            # Update start_time and end_time for next batch\n",
    "            start_time = end_time\n",
    "            end_time = str(datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\") + timedelta(**args))\n",
    "            \n",
    "            # Select the remaining portions at the end\n",
    "            if end_time >= end_time_train and not flag:\n",
    "                \n",
    "                end_time = end_time_train\n",
    "                flag = True   \n",
    "\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss/total_step)\n",
    "        print(f'\\ntrain loss: {np.mean(train_loss)}, train acc: {(100 * correct / total):.4f}')\n",
    "\n",
    "        # Combine predictions and labels collected from all batches\n",
    "        preds_ = torch.cat(preds_).detach().cpu().numpy()\n",
    "        targets_ = torch.cat(targets_).detach().cpu().numpy()\n",
    "        \n",
    "        f1score = f1_score(targets_, preds_,  average='macro')\n",
    "        if best_f1 < f1score:\n",
    "            best_f1 = f1score\n",
    "            # Save the best model \n",
    "            with open(\"./result/Driving_Behavior_Buffered_Fetch.txt\", \"a\") as text_file:\n",
    "                print('epoch=====',epoch, file=text_file)\n",
    "                print(classification_report(targets_, preds_, digits=4), file=text_file)\n",
    "            print('model save')\n",
    "            torch.save(model, f'./result/Driving_Behavior_Buffered_Fetch.pt') \n",
    "        epochs.set_postfix_str(f\"epoch = {epoch},  f1_score = {f1score}, best_f1 = {best_f1}\")\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf52d508c6e4049940d2af44d35bc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 1.2198508590459824, train acc: 28.3069\n",
      "model save\n",
      "\n",
      "train loss: 1.1598082239429157, train acc: 26.2678\n",
      "model save\n",
      "\n",
      "train loss: 1.107899581723743, train acc: 35.2562\n",
      "model save\n",
      "\n",
      "train loss: 1.0398582958383487, train acc: 46.1765\n",
      "model save\n",
      "\n",
      "train loss: 0.9808812577128994, train acc: 46.0961\n",
      "\n",
      "train loss: 0.939815077694382, train acc: 58.1701\n",
      "model save\n",
      "\n",
      "train loss: 0.8971152202351647, train acc: 68.6880\n",
      "model save\n",
      "\n",
      "train loss: 0.8542854312003783, train acc: 71.7467\n",
      "model save\n",
      "\n",
      "train loss: 0.8334455578039692, train acc: 70.3247\n",
      "\n",
      "train loss: 0.8017001299720323, train acc: 78.2935\n",
      "model save\n",
      "\n",
      "train loss: 0.7874872069343012, train acc: 63.5900\n",
      "\n",
      "train loss: 0.7601574423671537, train acc: 79.8229\n",
      "model save\n",
      "\n",
      "train loss: 0.7474860537818434, train acc: 77.5154\n",
      "\n",
      "train loss: 0.7221747141092021, train acc: 84.2501\n",
      "model save\n",
      "\n",
      "train loss: 0.7121277198212597, train acc: 81.9157\n",
      "\n",
      "train loss: 0.6894723783857291, train acc: 86.2087\n",
      "model save\n",
      "\n",
      "train loss: 0.6800033957081704, train acc: 83.7939\n",
      "\n",
      "train loss: 0.6610342711776946, train acc: 85.9136\n",
      "\n",
      "train loss: 0.6516000846898602, train acc: 85.9941\n",
      "\n",
      "train loss: 0.6355110575281989, train acc: 85.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (network): Sequential(\n",
       "    (0): TemporalBlock(\n",
       "      (conv1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "      (relu1): ReLU()\n",
       "      (dropout1): Dropout(p=0.05, inplace=False)\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "      (relu2): ReLU()\n",
       "      (dropout2): Dropout(p=0.05, inplace=False)\n",
       "      (net): Sequential(\n",
       "        (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.05, inplace=False)\n",
       "        (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): TemporalBlock(\n",
       "      (conv1): Conv1d(32, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
       "      (relu1): ReLU()\n",
       "      (dropout1): Dropout(p=0.05, inplace=False)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
       "      (relu2): ReLU()\n",
       "      (dropout2): Dropout(p=0.05, inplace=False)\n",
       "      (net): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.05, inplace=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), dilation=(2,))\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (downsample): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "epochs = trange(20, desc='training')\n",
    "# Unit of time ('days', 'hours', 'minutes', 'seconds')\n",
    "unit = 'minutes'\n",
    "Fetch_size = 30\n",
    "# Set Batch Size\n",
    "batch_size = 64\n",
    "# Set Train Time\n",
    "start_time_train = '2025-07-18 00:00:00'\n",
    "end_time_train = '2025-07-18 01:02:07'\n",
    "# Set up scalers\n",
    "scaler = MinMaxScaler()\n",
    "# Set Min, Max value\n",
    "Min, Max = set_minmax_value(URL, table, name, start_time_train, end_time_train)\n",
    "\n",
    "#################################################################Training#############################################################################################\n",
    "train(epochs, start_time_train, end_time_train, unit, Fetch_size, URL, table, name, timeformat, resample_freq, scaler, Min, Max, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, start_time_test, end_time_test, unit, Fetch_size, URL, table, name, timeformat, resample_freq, scaler, Min, Max, batch_size):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        # Initial settings \n",
    "        output_test = []\n",
    "        output_target = []\n",
    "        \n",
    "        # Set initial Time\n",
    "        args = {unit: Fetch_size}\n",
    "        start_time = start_time_test\n",
    "        end_time = str(datetime.strptime(start_time_test, \"%Y-%m-%d %H:%M:%S\") + timedelta(**args))\n",
    "        end_time_test_ = str(datetime.strptime(end_time_test, \"%Y-%m-%d %H:%M:%S\") + timedelta(minutes=1))\n",
    "        \n",
    "        # Set flag\n",
    "        flag = False\n",
    "        \n",
    "        while end_time < end_time_test_:\n",
    "            \n",
    "            # Load batch data\n",
    "            data = data_load(URL, table, name, start_time, end_time, timeformat, resample_freq)\n",
    "\n",
    "            # Rename the 'Class' column to 'label'\n",
    "            data.rename(columns={'Class': 'label'}, inplace=True)\n",
    "\n",
    "            # Move the 'label' column to the last position\n",
    "            data = data.reindex(columns=[col for col in data.columns if col != 'label'] + ['label'])\n",
    "\n",
    "            # Convert the 'label' column to integer type\n",
    "            data['label'] = data['label'].astype(int)\n",
    "\n",
    "            # Apply MinMaxscaler\n",
    "            data_scaled = scaler.fit_transform(data.iloc[:,:-1].values, Min.drop(columns=[0]).values, Max.drop(columns=[0]).values)\n",
    "            \n",
    "            # Set up the DataFrame\n",
    "            data_ = pd.DataFrame(data_scaled, index=data.index)\n",
    "            data_['label'] = data['label'].values\n",
    "            \n",
    "            # Set TimeFeatureGenerator\n",
    "            feature_generator = TimeFeatureGenerator()  \n",
    "            \n",
    "            # Make Time Featrue\n",
    "            time_feature = feature_generator.generate_features(data.index)\n",
    "            \n",
    "            # concat origin dataset\n",
    "            data_ = pd.concat([data_, time_feature], axis=1)\n",
    "            \n",
    "            # Drop NaN values\n",
    "            data = data_.dropna()\n",
    "\n",
    "            # Set up dataset & Loader\n",
    "            test_ = Driving_Dataset(data, target_column='label', seq_length=2)\n",
    "\n",
    "            test_dataloader = DataLoader(test_, batch_size, shuffle=False)\n",
    "            \n",
    "            # Print if the loaded data is empty\n",
    "            if len(data) != 0:\n",
    "                \n",
    "                for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "                    \n",
    "                    data = data.to(device).float()\n",
    "                    target = target.to(device).long().squeeze()\n",
    "                \n",
    "                    # Input to the model\n",
    "                    outputs = model(data)\n",
    "                    outputs = outputs.squeeze()\n",
    "                    \n",
    "                    # Set label predictions \n",
    "                    _,pred = torch.max(outputs, dim=1)\n",
    "                    target_ = target.view_as(pred)\n",
    "                    \n",
    "                    output_test.append(pred)\n",
    "                    output_target.append(target_)\n",
    "        \n",
    "            # Update start_time and end_time for next batch\n",
    "            start_time = end_time\n",
    "            end_time = str(datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\") + timedelta(**args))\n",
    "            \n",
    "            # Select the remaining portions at the end\n",
    "            if end_time >= end_time_test and not flag:\n",
    "                \n",
    "                end_time = end_time_test\n",
    "                flag = True   \n",
    " \n",
    "        # Combine tensors into one\n",
    "        combined_tensor_target = torch.cat(output_target, dim=0)\n",
    "        combined_tensor_pred = torch.cat(output_test, dim=0)\n",
    "\n",
    "        # Change to NumPy format\n",
    "        real_values = combined_tensor_target.cpu().numpy()\n",
    "        real_pred_values = combined_tensor_pred.cpu().numpy()\n",
    "\n",
    "    return real_values, real_pred_values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model_ = torch.load(f'./result/Driving_Behavior_Buffered_Fetch.pt')\n",
    "\n",
    "# Unit of time ('days', 'hours', 'minutes', 'seconds')\n",
    "unit = 'minutes'\n",
    "Fetch_size = 30\n",
    "# Set Test Time\n",
    "start_time_test = '2025-07-18 01:02:07'\n",
    "end_time_test = '2025-07-18 01:52:07'\n",
    "##################################################################################Test############################################################################################################\n",
    "real_values, real_pred_values = test(model_, start_time_test, end_time_test, unit, Fetch_size, URL, table, name, timeformat, resample_freq, scaler, Min, Max, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       997\n",
      "           1       1.00      0.89      0.94      1273\n",
      "           2       0.18      0.34      0.23       730\n",
      "\n",
      "    accuracy                           0.46      3000\n",
      "   macro avg       0.39      0.41      0.39      3000\n",
      "weighted avg       0.47      0.46      0.46      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_values, real_pred_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
