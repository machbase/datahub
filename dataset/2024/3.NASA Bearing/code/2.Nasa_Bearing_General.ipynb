{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## 사용 라이브러리 호출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## 모델 사용 라이브러리 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange\n",
    "import statistics\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "## 모델 학습 결과 경로 설정 \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Cuda 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 랜덤 시드 설정\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 시드 설정 \n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 데이터 컬럼 선택\n",
    "\n",
    "* tag name 이 많은 경우 tag name을 지정하는 것에 있어서 변수 설정이 다소 유연해짐\n",
    "* tag name 은 순서대로 불러와짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag name 출력 함수 \n",
    "def show_column(URL):\n",
    "    \n",
    "    # Tag name 데이터 로드\n",
    "    df = pd.read_csv(URL)\n",
    "    \n",
    "    # List 형식으로 변환\n",
    "    df = df.values.reshape(-1)\n",
    "    \n",
    "    return df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tag name 출력 파라미터 설정\n",
    "table = 'bearing'\n",
    "\n",
    "NAME_URL = f'http://127.0.0.1:5654/db/tql/datahub/api/v1/get_tag_names.tql?table={table}'\n",
    "\n",
    "## tag name list 생성 \n",
    "name = show_column(NAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1-c1',\n",
       " 's1-c2',\n",
       " 's1-c3',\n",
       " 's1-c4',\n",
       " 's1-c5',\n",
       " 's1-c6',\n",
       " 's1-c7',\n",
       " 's1-c8',\n",
       " 's2-c1',\n",
       " 's2-c2',\n",
       " 's2-c3',\n",
       " 's2-c4',\n",
       " 's3-c1',\n",
       " 's3-c2',\n",
       " 's3-c3',\n",
       " 's3-c4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG Name format 변환 \n",
    "\n",
    "* 위의 과정에서 Nasa bearing dataset의 모든 Tag Name 을 확인후 사용할 컬럼만 뽑아서 입력할 파라미터 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s1-c5'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 원하는 tag name 설정\n",
    "# 여기서 tag name 은 컬럼을 의미\n",
    "tags = ['s1-c5']\n",
    "\n",
    "# 리스트의 각 항목을 작은따옴표로 감싸고, 쉼표로 구분\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "\n",
    "# 사용 tag name 확인\n",
    "print(tags_)\n",
    "\n",
    "# 해당 값을 모델의 input shape로 설정 \n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasa Bearing Dataset 로드\n",
    "\n",
    "* 데이터 로드시 train, validation, test 데이터 셋을 각각 Load\n",
    "\n",
    "* 예제는 3번쨰 bearing의 이상탐지로 진행 -> 's1-c5' Tag Name 사용\n",
    "\n",
    "* 나머지 상태 빼고 고장이 아니면 전부 정상으로 labeling 해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 bearing의 상태를 시간 범위로 설정\n",
    "B1 ={\n",
    "    \"early\" : [\"2003-10-22 12:06:24\" , \"2003-10-23 09:14:13\"],\n",
    "    \"suspect\" : [\"2003-10-23 09:24:13\" , \"2003-11-08 12:11:44\"],\n",
    "    \"normal\" : [\"2003-11-08 12:21:44\" , \"2003-11-19 21:06:07\"],\n",
    "    \"suspect_1\" : [\"2003-11-19 21:16:07\" , \"2003-11-24 20:47:32\"],\n",
    "    \"imminent_failure\" : [\"2003-11-24 20:57:32\",\"2003-11-25 23:39:56\"]\n",
    "}\n",
    "B2 = {\n",
    "    \"early\" : [\"2003-10-22 12:06:24\" , \"2003-11-01 21:41:44\"],\n",
    "    \"normal\" : [\"2003-11-01 21:51:44\" , \"2003-11-24 01:01:24\"],\n",
    "    \"suspect\" : [\"2003-11-24 01:11:24\" , \"2003-11-25 10:47:32\"],\n",
    "    \"imminient_failure\" : [\"2003-11-25 10:57:32\" , \"2003-11-25 23:39:56\"]\n",
    "}\n",
    "\n",
    "B3 = {\n",
    "    \"early\" : [\"2003-10-22 12:06:24\" , \"2003-11-01 21:41:44\"],\n",
    "    \"normal\" : [\"2003-11-01 21:51:44\" , \"2003-11-22 09:16:56\"],\n",
    "    \"suspect\" : [\"2003-11-22 09:26:56\" , \"2003-11-25 10:47:32\"],\n",
    "    \"Inner_race_failure\" : [\"2003-11-25 10:57:32\" , \"2003-11-25 23:39:56\"]\n",
    "}\n",
    "\n",
    "B4 = {\n",
    "    \"early\" : [\"2003-10-22 12:06:24\" , \"2003-10-29 21:39:46\"],\n",
    "    \"normal\" : [\"2003-10-29 21:49:46\" , \"2003-11-15 05:08:46\"],\n",
    "    \"suspect\" : [\"2003-11-15 05:18:46\" , \"2003-11-18 19:12:30\"],\n",
    "    \"Rolling_element_failure\" : [\"2003-11-19 09:06:09\" , \"2003-11-22 17:36:56\"],\n",
    "    \"Stage_two_failure\" : [\"2003-11-22 17:46:56\" , \"2003-11-25 23:39:56\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 파라미터 설정\n",
    "\n",
    "# tag table 이름 설정\n",
    "table = 'bearing'\n",
    "# tag name 설정\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# 시간 포멧 설정 \n",
    "timeformat = quote('2006-01-02 15:04:05.000000')\n",
    "# Train , validation , test 데이터 셋 설정\n",
    "# 학습 데이터 시작 시간 설정\n",
    "start_time = quote('2003-10-22 12:06:24')\n",
    "# 학습 데이터  끝 시간 설정\n",
    "end_time = quote('2003-11-25 23:39:56')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "# 데이터 로드후 초당 데이터 개수를 판단후 부족한 데이터는 제거\n",
    "# 이후 같은 초의 데이터를 한줄로 만듬 \n",
    "def data_load(table, name, start_time, end_time, timeformat):\n",
    "    \n",
    "    # 데이터 로드 \n",
    "    df = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-rawdata.tql?table={table}&name={name}&start={start_time}&end={end_time}&timeformat={timeformat}')\n",
    "    \n",
    "    # 같은 시간대 별 데이터로 전환\n",
    "    df = df.pivot_table(index='TIME', columns='NAME', values='VALUE', aggfunc='first').reset_index()\n",
    "    \n",
    "    # time 설정\n",
    "    df['TIME'] = pd.to_datetime(df['TIME'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    # 초 단위로 그룹화하여 데이터 개수 세기\n",
    "    df_counts = df.groupby(df['TIME'].dt.floor('S')).size().reset_index(name='count')\n",
    "\n",
    "    # 데이터 개수가 동일한 그룹만 필터링\n",
    "    # count 값이 가장 많이 나타나는 값들을 선택\n",
    "    most_common_count = df_counts['count'].mode()[0]\n",
    "\n",
    "    # 가장 많이 나타나는 count 값으로 필터링\n",
    "    filtered_df_counts = df_counts[df_counts['count'] == most_common_count]\n",
    "\n",
    "    # 필터링된 시간값들을 리스트로 변환\n",
    "    filtered_times = filtered_df_counts['TIME'].tolist()\n",
    "\n",
    "    # 원본 데이터프레임에서 필터링된 시간값들만 선택\n",
    "    filtered_data = df[df['TIME'].dt.floor('S').isin(filtered_times)]\n",
    "\n",
    "    # TIME을 기준으로 그룹화\n",
    "    # 초 단위로 반올림\n",
    "    filtered_data_ = filtered_data.copy()\n",
    "    filtered_data_.loc[:, 'TIME'] = filtered_data_['TIME'].dt.floor('S')\n",
    "    grouped = filtered_data_.groupby('TIME')['s1-c5'].apply(list).reset_index()\n",
    "\n",
    "    # 리스트를 개별 열로 나누기\n",
    "    s1_c5_df = pd.DataFrame(grouped['s1-c5'].tolist())\n",
    "\n",
    "    # 'TIME' 열과 병합\n",
    "    result_df = pd.concat([grouped[['TIME']], s1_c5_df], axis=1)\n",
    "    \n",
    "    # label 설정\n",
    "    # 각 채널데이터 비정상부분의 시간 값을 기준으로 label 설정 \n",
    "    result_df['label'] = np.where((result_df['TIME'] >= \"2003-11-25 10:57:32\") & (result_df['TIME'] <= \"2003-11-25 23:39:56\"), 1, 0)\n",
    "    \n",
    "    result_df = result_df.drop(['TIME'], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20471</th>\n",
       "      <th>20472</th>\n",
       "      <th>20473</th>\n",
       "      <th>20474</th>\n",
       "      <th>20475</th>\n",
       "      <th>20476</th>\n",
       "      <th>20477</th>\n",
       "      <th>20478</th>\n",
       "      <th>20479</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>0.432</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.767</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>0.525</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2155 rows × 20481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0    -0.105 -0.049 -0.005 -0.100 -0.151  0.046 -0.132 -0.164 -0.110 -0.100   \n",
       "1    -0.083 -0.132 -0.081 -0.022 -0.129 -0.110 -0.149 -0.168 -0.225 -0.217   \n",
       "2    -0.122 -0.244 -0.156 -0.076  0.046 -0.098 -0.142  0.083 -0.195 -0.088   \n",
       "3    -0.210 -0.125 -0.090 -0.215 -0.225 -0.139 -0.042 -0.090 -0.142 -0.232   \n",
       "4    -0.088 -0.088 -0.110 -0.269  0.024 -0.054 -0.156 -0.205 -0.056 -0.132   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2150 -0.212 -0.095  0.044  0.005 -0.364 -0.239 -0.098 -0.066 -0.081 -0.164   \n",
       "2151  0.432  0.217 -0.627 -0.308  0.073  0.107 -0.359  0.056 -0.159 -0.181   \n",
       "2152 -0.112 -0.510  0.037  0.063 -0.115 -0.066  0.117  0.405 -0.374 -0.339   \n",
       "2153 -0.593  0.366 -0.393 -0.312 -0.156  0.288  0.122 -0.105  0.242 -0.166   \n",
       "2154  0.107  0.193 -0.176 -0.273 -0.015  0.630 -0.535 -0.596 -0.413  0.225   \n",
       "\n",
       "      ...  20471  20472  20473  20474  20475  20476  20477  20478  20479  \\\n",
       "0     ... -0.088 -0.107 -0.078 -0.093 -0.200 -0.159 -0.237 -0.027 -0.002   \n",
       "1     ... -0.129 -0.149 -0.046  0.007 -0.132 -0.073  0.056 -0.186 -0.049   \n",
       "2     ... -0.107 -0.061 -0.090 -0.049 -0.125 -0.056 -0.137 -0.247 -0.229   \n",
       "3     ... -0.046 -0.195 -0.085 -0.112 -0.049 -0.146 -0.154 -0.220 -0.090   \n",
       "4     ...  0.044 -0.122 -0.115 -0.056 -0.078 -0.002 -0.342 -0.173 -0.161   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2150  ... -0.574  0.127  0.767  0.173  0.217 -0.271  0.085  0.364 -0.166   \n",
       "2151  ... -0.161 -0.046 -0.098 -0.186 -0.251 -0.032 -0.017 -0.073 -0.437   \n",
       "2152  ... -0.188 -0.002 -0.085 -0.149 -0.195 -0.227 -0.095 -0.115 -0.293   \n",
       "2153  ...  0.510 -0.776 -0.483  0.288  0.359  0.120 -0.173 -0.400  0.505   \n",
       "2154  ... -0.244 -0.767 -0.994 -0.405  0.525 -0.010 -0.166 -0.415  0.046   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2150      1  \n",
       "2151      1  \n",
       "2152      1  \n",
       "2153      1  \n",
       "2154      1  \n",
       "\n",
       "[2155 rows x 20481 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "df = data_load(table, name, start_time, end_time, timeformat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 검증, 테스트 데이터 분리\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "valid, test = train_test_split(test, test_size=0.5, shuffle=False)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "* 각 데이터별로 hanning window, FFT, MinMax Scaling 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hanning window 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanning window 함수 설정 \n",
    "def set_hanning_window(sample_rate, df):\n",
    "    \n",
    "    # Hanning 윈도우 생성\n",
    "    hanning_window = np.hanning(sample_rate)\n",
    "\n",
    "    # 각 행에 Hanning 윈도우 적용\n",
    "    df_windowed = df.multiply(hanning_window, axis=1)\n",
    "    \n",
    "    return df_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "window_length = len(df.columns[:-1])\n",
    "\n",
    "train_ = set_hanning_window(window_length, train.iloc[:,:-1])\n",
    "valid_ = set_hanning_window(window_length, valid.iloc[:,:-1])\n",
    "test_ = set_hanning_window(window_length, test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT 변환 함수\n",
    "def change_fft(sample_rate, df):\n",
    "    # 신호의 총 샘플 수\n",
    "    N = sample_rate\n",
    "    \n",
    "    # 각 행에 대해 FFT 적용\n",
    "    fft_results = np.zeros((df.shape[0], N // 2 + 1), dtype=float)\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        # 각 행의 FFT 계산\n",
    "        yf = fft(df.iloc[i].values)\n",
    "        \n",
    "        # FFT 결과의 절댓값을 계산하고 정규화 (유의미한 부분만)\n",
    "        fft_results[i] = 2.0 / N * np.abs(yf[:N // 2 + 1])\n",
    "    \n",
    "    # FFT 결과를 데이터 프레임으로 변환\n",
    "    fft_df = pd.DataFrame(fft_results)\n",
    "    \n",
    "    return fft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링 주기 -> 초당 데이터 개수 \n",
    "sampling_rate = len(df.columns[:-1])\n",
    "\n",
    "# FFT 변환\n",
    "train_ = change_fft(sampling_rate, train_)\n",
    "valid_ = change_fft(sampling_rate, valid_)\n",
    "test_ = change_fft(sampling_rate, test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 설정\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 스케일러 적용\n",
    "train_ = scaler.fit_transform(train_.values)\n",
    "valid_ = scaler.transform(valid_.values)\n",
    "test_ = scaler.transform(test_.values)\n",
    "\n",
    "# 데이터 프레임 설정\n",
    "train_scaled = pd.DataFrame(train_)\n",
    "valid_scaled = pd.DataFrame(valid_)\n",
    "test_scaled = pd.DataFrame(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1724\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    215\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    181\n",
      "1     35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## PCA 적용\n",
    "# 95%의 분산을 설명하는 주성분 선택\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# 변환 \n",
    "train_scaled_ = pca.fit_transform(train_scaled)\n",
    "valid_scaled_ = pca.transform(valid_scaled)\n",
    "test_scaled_ = pca.transform(test_scaled)\n",
    "\n",
    "# 데이터 프레임 설정\n",
    "train_scaled_ = pd.DataFrame(train_scaled_)\n",
    "valid_scaled_ = pd.DataFrame(valid_scaled_)\n",
    "test_scaled_ = pd.DataFrame(test_scaled_)\n",
    "\n",
    "# label 추가\n",
    "train_scaled_['label'] = train['label'].values\n",
    "valid_scaled_['label'] = valid['label'].values\n",
    "test_scaled_['label'] = test['label'].values\n",
    "\n",
    "print(train_scaled_['label'].value_counts())\n",
    "print(valid_scaled_['label'].value_counts())\n",
    "print(test_scaled_['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 윈도우 데이터 셋 설정\n",
    "\n",
    "시계열 데이터 학습을 위해서는 윈도우 사이즈와 슬라이딩 값을 설정해야함\n",
    "\n",
    "* window size : 몇개의 시간으로 묶을지에 대한 설정\n",
    "* step size : window 가 이동하는 시간 간격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 데이터셋 설정 \n",
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, data, window_size, step_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.windows, self.labels = self._create_windows()\n",
    "    \n",
    "    # 슬라이딩 윈도우 설정\n",
    "    def _create_windows(self):\n",
    "        windows = []\n",
    "        labels = []\n",
    "        for i in range(0, len(self.data) - self.window_size + 1, self.step_size):\n",
    "            window = self.data.iloc[i:i + self.window_size, :-1].values  # 마지막 컬럼 제외\n",
    "            label_array = self.data.iloc[i:i + self.window_size, -1].values  # 마지막 컬럼이 label\n",
    "            \n",
    "            # 레이블 배열에서 하나라도 비정상 값이 있으면 레이블을 1로 설정\n",
    "            if (label_array == 1).any():\n",
    "                label = 1  \n",
    "            else:\n",
    "                label = 0\n",
    "                \n",
    "            windows.append(torch.Tensor(window))\n",
    "            labels.append(torch.Tensor([label]))  # label을 Tensor로 변환\n",
    "        return windows, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 설정\n",
    "window_size = 3\n",
    "step_size = 1 \n",
    "\n",
    "# 데이터 셋 설정 \n",
    "train_ = SlidingWindowDataset(train_scaled_, window_size, step_size)\n",
    "valid_ = SlidingWindowDataset(valid_scaled_, window_size, step_size)\n",
    "test_ = SlidingWindowDataset(test_scaled_, window_size, step_size)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_dataloader = DataLoader(train_, batch_size=32, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 1487])\n"
     ]
    }
   ],
   "source": [
    "print(list(train_dataloader)[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 \n",
    "\n",
    "* LSTM AE 기본 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder 클래스 정의\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        \n",
    "        # 인코더 LSTM\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.encoder_fc = nn.Linear(hidden_dim, 2*hidden_dim)\n",
    "        \n",
    "        # 디코더 LSTM\n",
    "        self.decoder_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더 부분\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        latent = self.encoder_fc(h[-1])\n",
    "        \n",
    "        # 디코더 부분\n",
    "        hidden = self.decoder_fc(latent).unsqueeze(0).repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        output, _ = self.decoder_lstm(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMAutoencoder(\n",
      "  (encoder_lstm): LSTM(1487, 256, num_layers=3, batch_first=True)\n",
      "  (encoder_fc): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (decoder_fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (decoder_lstm): LSTM(256, 1487, num_layers=3, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 파라미터\n",
    "\n",
    "# 입력 데이터 컬럼 수\n",
    "# PCA 한값 \n",
    "# print(list(train_dataloader)[0][0].shape) 에서 마지막 숫자 \n",
    "input_dim = 1487\n",
    "\n",
    "# LSMT hidden state 크기\n",
    "hidden_dim = 256\n",
    "\n",
    "# layer 수\n",
    "num_layers = 3\n",
    "\n",
    "# 학습률 \n",
    "learning_rate = 0.01\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMAutoencoder(input_dim, hidden_dim, num_layers).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 설정\n",
    "\n",
    "* 학습 중 Loss 값이 제일 높은 모델을 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcb3192e00b465db6f551c4b3070734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.1874480980137984\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.18224455574872317\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.18051004501772516\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17964278979019987\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17912243715039006\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17877553511456945\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17852774798554719\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17834190784574105\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.17819736530015498\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.1780817310705229\n",
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "total_step = len(train_dataloader)\n",
    "epoch_in = trange(10, desc='training')\n",
    "best_Loss= np.inf\n",
    "\n",
    "for epoch in epoch_in:\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    preds_ = []\n",
    "    targets_ = []\n",
    "\n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = train_data[0].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    " \n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss)}')\n",
    "\n",
    "    \n",
    "    if best_Loss > np.mean(train_loss):\n",
    "        best_Loss = np.mean(train_loss)\n",
    "        torch.save(model, f'./result/Nasa_Bearing_LSTM_AE_General2_비지도.pt')\n",
    "        print('모델 저장')\n",
    "    epoch_in.set_postfix_str(f\"epoch = {epoch}, best_Loss = {best_Loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임계값 설정\n",
    "\n",
    "* validation data를 사용하여 임계값 계산 \n",
    "  * Max + K x 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델 로드\n",
    "model_ = torch.load(f'./result/Nasa_Bearing_LSTM_AE_General2_비지도.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18937314544431605\n"
     ]
    }
   ],
   "source": [
    "# validation data 재구성 Loss 계산 \n",
    "valid_loss = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, valid_data in enumerate(valid_dataloader):\n",
    "\n",
    "        inputs_val = valid_data[0].to(device).float()\n",
    "\n",
    "        outputs_val = model_(inputs_val)\n",
    "        loss = criterion(outputs_val, inputs_val)\n",
    "        \n",
    "        valid_loss.append(loss.item())\n",
    "        \n",
    "# 임계값 설정\n",
    "# 임계값은 본인이 세운 기준으로 맞추는 것\n",
    "# 해당 임계값은 Max + K x 표준편차 로 구성, validation 기준으로 k 값을 조정 \n",
    "threshold =  max(valid_loss) + 10*statistics.stdev(valid_loss)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트\n",
    "\n",
    "* 이전 단계에서 계산한 임계값을 기준으로 테스트 데이터를 통한 모델 테스트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 모델 적용 \n",
    "test_loss = []\n",
    "test_label = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, test_data in enumerate(test_dataloader):\n",
    "\n",
    "        inputs_test = test_data[0].to(device).float()\n",
    "        label = test_data[1].to(device).long()\n",
    "\n",
    "        outputs_test = model_(inputs_test)\n",
    "        loss = criterion(outputs_test, inputs_test)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        test_label.append(label.item())\n",
    "\n",
    "# 테스트 결과 데이터 프레임 생성\n",
    "result = pd.DataFrame(test_loss, columns=['Reconst_Loss'])\n",
    "\n",
    "# 실제 label 설정 \n",
    "result['label'] = test_label\n",
    "\n",
    "# 각 임계값 기준 정상, 비정상 구분\n",
    "result['pred'] = np.where(result['Reconst_Loss']>threshold,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 평가\n",
    "\n",
    "* F1 Score 기준으로 평가 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       179\n",
      "           1       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00       214\n",
      "   macro avg       1.00      1.00      1.00       214\n",
      "weighted avg       1.00      1.00      1.00       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max + 10 x 표준편차 임계값 test 기준 F1 Score 출력 \n",
    "print(classification_report(result['label'], result['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과적합 체크\n",
    "\n",
    "* test 데이터뿐만 아니라 train, validation 데이터를 활용해 F1 score 계산\n",
    "* 만약 train, validation 결과가 좋지 않다면 모델 과적합으로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 모델 적용 \n",
    "train_loss = []\n",
    "train_label = []\n",
    "train_dataloader = DataLoader(train_, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs_train = train_data[0].to(device).float()\n",
    "        label = train_data[1].to(device).long()\n",
    "\n",
    "        outputs_train = model_(inputs_train)\n",
    "        loss = criterion(outputs_train, inputs_train)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        train_label.append(label.item())\n",
    "\n",
    "# 테스트 결과 데이터 프레임 생성\n",
    "result = pd.DataFrame(train_loss, columns=['Reconst_Loss'])\n",
    "\n",
    "# 실제 label 설정 \n",
    "result['label'] = train_label\n",
    "\n",
    "# 각 임계값 기준 정상, 비정상 구분\n",
    "result['pred'] = np.where(result['Reconst_Loss']>threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.90      1722\n",
      "\n",
      "   micro avg       1.00      0.83      0.90      1722\n",
      "   macro avg       1.00      0.83      0.90      1722\n",
      "weighted avg       1.00      0.83      0.90      1722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max + 10 x 표준편차 임계값 train 기준 F1 Score 출력 \n",
    "print(classification_report(result['label'], result['pred'],labels=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 모델 적용 \n",
    "val_loss = []\n",
    "val_label = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, valid_data in enumerate(valid_dataloader):\n",
    "\n",
    "        inputs_val = valid_data[0].to(device).float()\n",
    "        label = valid_data[1].to(device).long()\n",
    "\n",
    "        outputs_val = model_(inputs_val)\n",
    "        loss = criterion(outputs_val, inputs_val)\n",
    "        \n",
    "        val_loss.append(loss.item())\n",
    "        val_label.append(label.item())\n",
    "\n",
    "# 테스트 결과 데이터 프레임 생성\n",
    "result = pd.DataFrame(val_loss, columns=['Reconst_Loss'])\n",
    "\n",
    "# 실제 label 설정 \n",
    "result['label'] = val_label\n",
    "\n",
    "# 각 임계값 기준 정상, 비정상 구분\n",
    "result['pred'] = np.where(result['Reconst_Loss']>threshold,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       213\n",
      "\n",
      "    accuracy                           1.00       213\n",
      "   macro avg       1.00      1.00      1.00       213\n",
      "weighted avg       1.00      1.00      1.00       213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max + 10 x 표준편차 임계값 validation 기준 F1 Score 출력 \n",
    "print(classification_report(result['label'], result['pred'],labels=[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
