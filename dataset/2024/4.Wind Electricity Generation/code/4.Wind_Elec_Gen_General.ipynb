{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## 사용 라이브러리 호출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## 모델 사용 라이브러리 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "## 모델 학습 결과 경로 설정 \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Cuda 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 랜덤 시드 설정\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 시드 설정 \n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 데이터 컬럼 선택\n",
    "\n",
    "* tag name 이 많은 경우 tag name을 지정하는 것에 있어서 변수 설정이 다소 유연해짐\n",
    "* tag name 은 순서대로 불러와짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag name 출력 함수 \n",
    "def show_column(URL):\n",
    "    \n",
    "    # Tag name 데이터 로드\n",
    "    df = pd.read_csv(URL)\n",
    "    \n",
    "    # List 형식으로 변환\n",
    "    df = df.values.reshape(-1)\n",
    "    \n",
    "    return df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tag name 출력 파라미터 설정\n",
    "table = 'wind_elec_gen'\n",
    "\n",
    "NAME_URL = f'http://127.0.0.1:5654/db/tql/datahub/api/v1/get_tag_names.tql?table={table}'\n",
    "\n",
    "## tag name list 생성 \n",
    "name = show_column(NAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h_6hrain',\n",
       " 'h_6hsnow',\n",
       " 'h_humidity',\n",
       " 'h_rainprobability',\n",
       " 'h_raintype',\n",
       " 'h_seawave',\n",
       " 'h_skystatus',\n",
       " 'h_temperature',\n",
       " 'h_winddirection',\n",
       " 'h_windspeed',\n",
       " 'hk1_1',\n",
       " 'hk1_2',\n",
       " 'hk1_3',\n",
       " 'hk2_1',\n",
       " 'hk2_2',\n",
       " 'hk2_3',\n",
       " 'hk2_4',\n",
       " 'hk2_5',\n",
       " 's_6hrain',\n",
       " 's_6hsnow',\n",
       " 's_humidity',\n",
       " 's_rainprobability',\n",
       " 's_raintype',\n",
       " 's_seawave',\n",
       " 's_skystatus',\n",
       " 's_temperature',\n",
       " 's_winddirection',\n",
       " 's_windspeed',\n",
       " 'ss_1',\n",
       " 'ss_10',\n",
       " 'ss_2',\n",
       " 'ss_3',\n",
       " 'ss_4',\n",
       " 'ss_5',\n",
       " 'ss_6',\n",
       " 'ss_7',\n",
       " 'ss_8',\n",
       " 'ss_9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG Name format 변환 \n",
    "\n",
    "* 위의 과정에서 Wind Elec Gen dataset의 모든 Tag Name 을 확인후 사용할 컬럼만 뽑아서 입력할 파라미터 형태로 변환\n",
    "* 한경 제 1 발전소 관련 Tag Name 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'h_6hrain','h_6hsnow','h_humidity','h_rainprobability','h_raintype','h_seawave','h_skystatus','h_temperature','h_winddirection','h_windspeed','hk1_1','hk1_2','hk1_3'\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# 원하는 tag name 설정\n",
    "# 여기서 tag name 은 컬럼을 의미\n",
    "tags = name[:13]\n",
    "\n",
    "# 리스트의 각 항목을 작은따옴표로 감싸고, 쉼표로 구분\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "\n",
    "# 사용 tag name 확인\n",
    "print(tags_)\n",
    "\n",
    "# 해당 값을 모델의 input shape로 설정 \n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Elec Gen Dataset 로드\n",
    "\n",
    "* 한경 제 1 발전소 관련 Tag Name 들을 사용하여 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 파라미터 설정\n",
    "\n",
    "# tag table 이름 설정\n",
    "table = 'wind_elec_gen'\n",
    "# tag name 설정\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# 시간 포멧 설정 \n",
    "timeformat = 'default'\n",
    "# Train , validation , test 데이터 셋 설정\n",
    "# 학습 데이터 시작 시간 설정\n",
    "start_time = quote('2014-01-01 06:00:00')\n",
    "# 학습 데이터  끝 시간 설정\n",
    "end_time = quote('2018-01-01 03:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "# 시간대를 맞추기 위해 3시간으로 resampling\n",
    "# target 값으로 사용할 통합 발전량 계산후 추가 \n",
    "def data_load(table, name, start_time, end_time, timeformat):\n",
    "    \n",
    "    # 데이터 로드 \n",
    "    df = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-rawdata.tql?table={table}&name={name}&start={start_time}&end={end_time}&timeformat={timeformat}')\n",
    "\n",
    "    # 같은 시간대 별 데이터로 전환\n",
    "    df = df.pivot_table(index='TIME', columns='NAME', values='VALUE', aggfunc='first').reset_index()\n",
    "\n",
    "    # 'TIME' 열을 datetime 형식으로 변환\n",
    "    df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "\n",
    "    # time index 설정\n",
    "    df.set_index('TIME', inplace=True)\n",
    "\n",
    "    # 3시간 간격으로 reampling \n",
    "    df = df.resample('3H').mean()\n",
    "\n",
    "    # 결측값 제거\n",
    "    df = df.dropna()\n",
    "\n",
    "    # 발전량 병합\n",
    "    # 한경 발전소의 1, 2, 3 발전량을 합침\n",
    "    df.loc[:, 'hk1_total'] = df.iloc[:, 10:].sum(axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NAME</th>\n",
       "      <th>h_6hrain</th>\n",
       "      <th>h_6hsnow</th>\n",
       "      <th>h_humidity</th>\n",
       "      <th>h_rainprobability</th>\n",
       "      <th>h_raintype</th>\n",
       "      <th>h_seawave</th>\n",
       "      <th>h_skystatus</th>\n",
       "      <th>h_temperature</th>\n",
       "      <th>h_winddirection</th>\n",
       "      <th>h_windspeed</th>\n",
       "      <th>hk1_1</th>\n",
       "      <th>hk1_2</th>\n",
       "      <th>hk1_3</th>\n",
       "      <th>hk1_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 06:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1327.916667</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>1328.900000</td>\n",
       "      <td>2652.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 09:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>285.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>849.011111</td>\n",
       "      <td>345.961111</td>\n",
       "      <td>813.372222</td>\n",
       "      <td>2008.344444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>278.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>543.388889</td>\n",
       "      <td>522.255556</td>\n",
       "      <td>533.427778</td>\n",
       "      <td>1599.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 15:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>281.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>489.533333</td>\n",
       "      <td>472.450000</td>\n",
       "      <td>461.377778</td>\n",
       "      <td>1423.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 18:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>369.827778</td>\n",
       "      <td>266.494444</td>\n",
       "      <td>342.866667</td>\n",
       "      <td>979.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-09 18:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>170.116667</td>\n",
       "      <td>169.338889</td>\n",
       "      <td>144.744444</td>\n",
       "      <td>484.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-09 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>267.794444</td>\n",
       "      <td>435.411111</td>\n",
       "      <td>416.900000</td>\n",
       "      <td>1120.105556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10 00:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>484.464706</td>\n",
       "      <td>669.894118</td>\n",
       "      <td>702.876471</td>\n",
       "      <td>1857.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10 03:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>558.694444</td>\n",
       "      <td>703.400000</td>\n",
       "      <td>853.727778</td>\n",
       "      <td>2115.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10 06:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>110.866667</td>\n",
       "      <td>1332.588889</td>\n",
       "      <td>1315.866667</td>\n",
       "      <td>2759.322222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8679 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NAME                 h_6hrain  h_6hsnow  h_humidity  h_rainprobability  \\\n",
       "TIME                                                                     \n",
       "2014-01-01 06:00:00       0.0       0.0        43.0                0.0   \n",
       "2014-01-01 09:00:00       0.0       0.0        50.0                0.0   \n",
       "2014-01-01 12:00:00       0.0       0.0        50.0                0.0   \n",
       "2014-01-01 15:00:00       0.0       0.0        50.0                0.0   \n",
       "2014-01-01 18:00:00       0.0       0.0        50.0                0.0   \n",
       "...                       ...       ...         ...                ...   \n",
       "2017-12-09 18:00:00       0.0       0.0        65.0               20.0   \n",
       "2017-12-09 21:00:00       0.0       0.0        65.0               20.0   \n",
       "2017-12-10 00:00:00       5.0       0.0        70.0               60.0   \n",
       "2017-12-10 03:00:00       5.0       0.0        50.0               60.0   \n",
       "2017-12-10 06:00:00       0.0       0.0        50.0               20.0   \n",
       "\n",
       "NAME                 h_raintype  h_seawave  h_skystatus  h_temperature  \\\n",
       "TIME                                                                     \n",
       "2014-01-01 06:00:00         0.0        1.5          1.0           12.1   \n",
       "2014-01-01 09:00:00         0.0        1.0          1.0           10.6   \n",
       "2014-01-01 12:00:00         0.0        1.0          1.0           10.2   \n",
       "2014-01-01 15:00:00         0.0        1.0          1.0            8.4   \n",
       "2014-01-01 18:00:00         0.0        1.0          1.0            8.0   \n",
       "...                         ...        ...          ...            ...   \n",
       "2017-12-09 18:00:00         0.0        0.5          3.0           10.0   \n",
       "2017-12-09 21:00:00         0.0        0.5          3.0           10.0   \n",
       "2017-12-10 00:00:00         0.0        1.0          4.0           11.0   \n",
       "2017-12-10 03:00:00         0.0        1.5          4.0           13.0   \n",
       "2017-12-10 06:00:00         0.0        1.5          3.0           12.0   \n",
       "\n",
       "NAME                 h_winddirection  h_windspeed        hk1_1        hk1_2  \\\n",
       "TIME                                                                          \n",
       "2014-01-01 06:00:00            285.0          8.1  1327.916667    -4.666667   \n",
       "2014-01-01 09:00:00            285.0          8.0   849.011111   345.961111   \n",
       "2014-01-01 12:00:00            278.0          8.2   543.388889   522.255556   \n",
       "2014-01-01 15:00:00            281.0          6.9   489.533333   472.450000   \n",
       "2014-01-01 18:00:00            298.0          6.4   369.827778   266.494444   \n",
       "...                              ...          ...          ...          ...   \n",
       "2017-12-09 18:00:00            220.0          5.1   170.116667   169.338889   \n",
       "2017-12-09 21:00:00            223.0          5.3   267.794444   435.411111   \n",
       "2017-12-10 00:00:00            254.0          5.8   484.464706   669.894118   \n",
       "2017-12-10 03:00:00            277.0          7.0   558.694444   703.400000   \n",
       "2017-12-10 06:00:00            302.0         10.7   110.866667  1332.588889   \n",
       "\n",
       "NAME                       hk1_3    hk1_total  \n",
       "TIME                                           \n",
       "2014-01-01 06:00:00  1328.900000  2652.150000  \n",
       "2014-01-01 09:00:00   813.372222  2008.344444  \n",
       "2014-01-01 12:00:00   533.427778  1599.072222  \n",
       "2014-01-01 15:00:00   461.377778  1423.361111  \n",
       "2014-01-01 18:00:00   342.866667   979.188889  \n",
       "...                          ...          ...  \n",
       "2017-12-09 18:00:00   144.744444   484.200000  \n",
       "2017-12-09 21:00:00   416.900000  1120.105556  \n",
       "2017-12-10 00:00:00   702.876471  1857.235294  \n",
       "2017-12-10 03:00:00   853.727778  2115.822222  \n",
       "2017-12-10 06:00:00  1315.866667  2759.322222  \n",
       "\n",
       "[8679 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = data_load(table, name, start_time, end_time, timeformat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test 데이터 분리\n",
    "# valid 2016년 , test 2017년, train 2016년 이전 데이터로 구성 \n",
    "\n",
    "train = df[df.index.year < 2016]\n",
    "valid = df[df.index.year == 2016]\n",
    "test = df[df.index.year == 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "   * 각 데이터 별로 MinMaxScaler 적용\n",
    "   * 입력 데이터와 targer 데이터 각각 적용 -> test 이후 원래 값으로 변환하기 위함     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 설정\n",
    "scaler_data = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# 스케일러 적용\n",
    "train_ = scaler_data.fit_transform(train.iloc[:,:-1].values)\n",
    "train_t = scaler_target.fit_transform(train.iloc[:,-1:].values)\n",
    "\n",
    "valid_ = scaler_data.transform(valid.iloc[:,:-1].values)\n",
    "valid_t = scaler_target.transform(valid.iloc[:,-1:].values)\n",
    "\n",
    "test_ = scaler_data.transform(test.iloc[:,:-1].values)\n",
    "test_t = scaler_target.transform(test.iloc[:,-1:].values)\n",
    "\n",
    "# 데이터 프레임 설정\n",
    "train_scaled = pd.DataFrame(train_)\n",
    "train_scaled['total'] = train_t\n",
    "\n",
    "valid_scaled = pd.DataFrame(valid_)\n",
    "valid_scaled['total'] = valid_t\n",
    "\n",
    "test_scaled = pd.DataFrame(test_)\n",
    "test_scaled['total'] = test_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 윈도우 데이터 셋 설정\n",
    "\n",
    "시계열 데이터 학습을 위해서는 윈도우 사이즈와 슬라이딩 값을 설정해야함\n",
    "\n",
    "* window size : 몇개의 시간으로 묶을지에 대한 설정\n",
    "* step size : window 가 이동하는 시간 간격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 데이터셋 설정 \n",
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, data, window_size, step_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.windows, self.targets = self._create_windows()\n",
    "    \n",
    "    # 슬라이딩 윈도우 설정\n",
    "    def _create_windows(self):\n",
    "        windows = []\n",
    "        targets = []\n",
    "        for i in range(0, len(self.data) - self.window_size + 1, self.step_size):\n",
    "            window = self.data.iloc[i:i + self.window_size, :-1].values  # 마지막 컬럼 제외\n",
    "            target_array = self.data.iloc[i:i + self.window_size, -1].values  # 마지막 컬럼이 target\n",
    "                \n",
    "            windows.append(torch.Tensor(window))\n",
    "            targets.append(torch.Tensor(target_array))  # target을 Tensor로 변환\n",
    "        return windows, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 설정\n",
    "window_size = 8\n",
    "step_size = 1 \n",
    "\n",
    "# 데이터 셋 설정 \n",
    "train_ = SlidingWindowDataset(train_scaled, window_size, step_size)\n",
    "valid_ = SlidingWindowDataset(valid_scaled, window_size, step_size)\n",
    "test_ = SlidingWindowDataset(test_scaled, window_size, step_size)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_dataloader = DataLoader(train_, batch_size=16, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(test_, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8, 13])\n"
     ]
    }
   ],
   "source": [
    "print(list(train_dataloader)[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 \n",
    "\n",
    "* LSTM AE 기본 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder 클래스 정의\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        \n",
    "        # 인코더 LSTM\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.encoder_fc = nn.Linear(hidden_dim, int(hidden_dim/2))\n",
    "        \n",
    "        # 디코더 LSTM\n",
    "        self.decoder_fc = nn.Linear(int(hidden_dim/2), hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # FC Layer 설정\n",
    "        self.fc1 = nn.Linear(input_dim,6)\n",
    "        self.fc2 = nn.Linear(6,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더 부분\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        latent = self.encoder_fc(h[-1])\n",
    "        \n",
    "        # 디코더 부분\n",
    "        hidden = self.decoder_fc(latent).unsqueeze(0).repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        output, _ = self.decoder_lstm(hidden)\n",
    "        \n",
    "        # FC Layer\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMAutoencoder(\n",
      "  (encoder_lstm): LSTM(13, 6, num_layers=2, batch_first=True)\n",
      "  (encoder_fc): Linear(in_features=6, out_features=3, bias=True)\n",
      "  (decoder_fc): Linear(in_features=3, out_features=6, bias=True)\n",
      "  (decoder_lstm): LSTM(6, 13, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=13, out_features=6, bias=True)\n",
      "  (fc2): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 파라미터\n",
    "\n",
    "# 입력 데이터 컬럼 수\n",
    "# PCA 한값 \n",
    "# print(list(train_dataloader)[0][0].shape) 에서 마지막 숫자 \n",
    "input_dim = 13\n",
    "\n",
    "# LSMT hidden state 크기\n",
    "hidden_dim = 6\n",
    "\n",
    "# layer 수\n",
    "num_layers = 2\n",
    "\n",
    "# 학습률 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMAutoencoder(input_dim, hidden_dim, num_layers).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 설정\n",
    "\n",
    "* 학습 중 validation 데이터 기준 MSE 값이 제일 낮은 모델을 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c83a45fe7fa4604bced2de6d6a7a17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.10497798808733219\n",
      "모델 저장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 8])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.07009734050156492\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.05669249567678885\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.049581676118025504\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.045194014430526744\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.04221041940257931\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.03963830807391609\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.03658906462113043\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.03393602749237281\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.031726155835246676\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.029874271303527947\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.02830658092610833\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.026967094588272726\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.025805254146957373\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.024788053555734043\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.02389106182117813\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.02309332792600077\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.022380577562833032\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.02173865216391254\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.021157986733682924\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.020629771659825387\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.02014707549242262\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.019704050160345307\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0192958359218911\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.018918352843827545\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.018568161532814622\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.018242345232504238\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0179384161695434\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.017654247815368167\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.017388017685795374\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.017138098863587234\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.016902952849399397\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.016681204180888223\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.016471676647626842\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.016273330495326043\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.016085242948795275\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0159065932502379\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01573664807664631\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.015574749482825436\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.015420305077994249\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.015272780116649962\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.015131690467835534\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.014996596928169265\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.014867100096781159\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01474283603911528\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01462347286355263\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.014508707655002086\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.014398263778628032\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01429188846295058\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01418935015618707\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.014090435966433038\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013994949204432252\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013902707102846865\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013813538963736108\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013727284375393707\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01364379192364738\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013562917965045168\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013484526084004463\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013408487028259728\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013334679496242894\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013262991205202435\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01319331966065756\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013125571968263014\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.013059663521232081\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012995516067934473\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012933055682916257\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012872211298998633\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012812913929249192\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012755096608980557\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01269869474772453\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012643646508742582\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012589892996586163\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012537378163909993\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012486048573639821\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012435853042632831\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012386742311075416\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012338668596328513\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012291585201950684\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01224544597629359\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012200204606791288\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012155813651071289\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012112223077241809\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012069377890292879\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.012027214285203308\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0119856530550976\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011944588815404932\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01190387544326832\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011863318688962147\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011822685507328878\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011781716335746685\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011740229095397504\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01169806758054445\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011655084437696773\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011611284622314168\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.01156638515785591\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011520194869713835\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011472430750909307\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011422872987553378\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011371571047007457\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.011319182488394603\n",
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "total_step = len(train_dataloader)\n",
    "total_step_ = len(valid_dataloader)\n",
    "epoch_in = trange(100, desc='training')\n",
    "best_Loss= np.inf\n",
    "\n",
    "for epoch in epoch_in:\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = train_data[0].to(device).float()\n",
    "        target = train_data[1].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss)}')\n",
    "    \n",
    "    # Epoch 마다 validation을 진행해서 가장 좋은 성능을 보이는 모델을 저장 \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss_ = 0.0\n",
    "        \n",
    "        for batch_idx, valid_data in enumerate(valid_dataloader):\n",
    "            \n",
    "            inputs_ = valid_data[0].to(device).float()\n",
    "            target_ = valid_data[1].to(device).float()\n",
    "\n",
    "            outputs_ = model(inputs_)\n",
    "            \n",
    "            loss_ = criterion(outputs_.squeeze(), target_)\n",
    "            \n",
    "            running_loss_ += loss_.item()\n",
    "            \n",
    "        valid_loss.append(running_loss_/total_step_)    \n",
    "\n",
    "    \n",
    "    if best_Loss > np.mean(valid_loss):\n",
    "        best_Loss = np.mean(valid_loss)\n",
    "        torch.save(model, f'./result/Wind_Elec_Gen_General.pt')\n",
    "        print('모델 저장')\n",
    "    epoch_in.set_postfix_str(f\"epoch = {epoch}, best_Loss = {best_Loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델 로드\n",
    "model_ = torch.load(f'./result/Wind_Elec_Gen_General.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트 \n",
    "output_test = []\n",
    "with torch.no_grad():\n",
    "    model_.eval()\n",
    "    running_loss_t = 0.0\n",
    "    \n",
    "    for batch_idx, test_data in enumerate(test_dataloader):\n",
    "        \n",
    "        inputs_t = test_data[0].to(device).float()\n",
    "        target_t = test_data[1].to(device).float()\n",
    "\n",
    "        outputs_t = model_(inputs_t)\n",
    "        \n",
    "        output_test.append(outputs_t)\n",
    "        \n",
    "# 텐서들을 하나로 합치기\n",
    "combined_tensor = torch.cat(output_test, dim=0)\n",
    "\n",
    "# window의 마지막 값만 사용하기\n",
    "last_values = combined_tensor[:, -1, :].cpu()\n",
    "\n",
    "# 원래 형태의 데이터로 변환\n",
    "# MinMaxScaler 역변환 \n",
    "last_values_ = scaler_target.inverse_transform(last_values)\n",
    "\n",
    "# 결과 데이터 프레임 생성\n",
    "final_scaled = pd.DataFrame(test_scaled.iloc[7:,-1:].values, columns=['real'])\n",
    "final_scaled['pred'] = last_values\n",
    "\n",
    "final = pd.DataFrame(test.iloc[7:, -1:].values, columns=['real'])\n",
    "final['pred'] = last_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.004653917329540123\n",
      "R² Score: 0.944772949282327\n"
     ]
    }
   ],
   "source": [
    "# MSE 계산\n",
    "mse = mean_squared_error(final_scaled['real'].values, final_scaled['pred'].values)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# R² 스코어 계산\n",
    "r2 = r2_score(final['real'].values, final['pred'].values)\n",
    "print(\"R² Score:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
