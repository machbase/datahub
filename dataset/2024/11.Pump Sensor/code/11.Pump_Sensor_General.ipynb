{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote, unquote\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Import libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "## Set path for saving model training results  \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Set Cuda for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## Set random seed\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Set seed\n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data Columns\n",
    "* Tag names are loaded in sequential order.\n",
    "* The process of selecting the required tag names from the tag name list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display tag names\n",
    "def show_column(URL):\n",
    "    \n",
    "    # Load tag name data\n",
    "    df = pd.read_csv(URL)\n",
    "    \n",
    "    # Convert to list format\n",
    "    df = df.values.reshape(-1)\n",
    "    \n",
    "    return df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parameters for displaying tag names\n",
    "table = 'pump'\n",
    "\n",
    "NAME_URL = f'http://127.0.0.1:5654/db/tql/datahub/api/v1/get_tag_names.tql?table={table}'\n",
    "\n",
    "## Generate tag name list \n",
    "name = show_column(NAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine_status',\n",
       " 'sensor_01',\n",
       " 'sensor_02',\n",
       " 'sensor_03',\n",
       " 'sensor_04',\n",
       " 'sensor_05',\n",
       " 'sensor_10',\n",
       " 'sensor_11',\n",
       " 'sensor_12',\n",
       " 'sensor_13',\n",
       " 'sensor_14',\n",
       " 'sensor_16',\n",
       " 'sensor_17',\n",
       " 'sensor_18',\n",
       " 'sensor_19',\n",
       " 'sensor_20',\n",
       " 'sensor_21',\n",
       " 'sensor_22',\n",
       " 'sensor_23',\n",
       " 'sensor_24',\n",
       " 'sensor_25',\n",
       " 'sensor_26',\n",
       " 'sensor_27',\n",
       " 'sensor_28',\n",
       " 'sensor_29',\n",
       " 'sensor_30',\n",
       " 'sensor_31',\n",
       " 'sensor_32',\n",
       " 'sensor_33',\n",
       " 'sensor_34',\n",
       " 'sensor_35',\n",
       " 'sensor_36',\n",
       " 'sensor_37',\n",
       " 'sensor_38',\n",
       " 'sensor_39',\n",
       " 'sensor_40',\n",
       " 'sensor_41',\n",
       " 'sensor_42',\n",
       " 'sensor_43',\n",
       " 'sensor_44',\n",
       " 'sensor_45',\n",
       " 'sensor_46',\n",
       " 'sensor_47',\n",
       " 'sensor_48',\n",
       " 'sensor_49']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting TAG Name Format\n",
    "* After checking all the Tag Names from the pump dataset in the previous step, extract only the columns to be used and convert them into parameter format.\n",
    "* Use all tag names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'machine_status','sensor_01','sensor_02','sensor_03','sensor_04','sensor_05','sensor_10','sensor_11','sensor_12','sensor_13','sensor_14','sensor_16','sensor_17','sensor_18','sensor_19','sensor_20','sensor_21','sensor_22','sensor_23','sensor_24','sensor_25','sensor_26','sensor_27','sensor_28','sensor_29','sensor_30','sensor_31','sensor_32','sensor_33','sensor_34','sensor_35','sensor_36','sensor_37','sensor_38','sensor_39','sensor_40','sensor_41','sensor_42','sensor_43','sensor_44','sensor_45','sensor_46','sensor_47','sensor_48','sensor_49'\n"
     ]
    }
   ],
   "source": [
    "# Set the desired tag names\n",
    "tags = name\n",
    "\n",
    "# Wrap each item in the list with single quotes and separate with commas\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "\n",
    "# Check the selected tag names\n",
    "print(tags_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pump Sensor Dataset\n",
    "* Load the data using all tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading parameter settings\n",
    "\n",
    "# Set the tag table name\n",
    "table = 'pump'\n",
    "# Set the tag names\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# Set the time format \n",
    "timeformat = 'default'\n",
    "# Set the data start time\n",
    "start_time = quote('2018-04-01 00:00:00')\n",
    "# Set the data end time\n",
    "end_time = quote('2018-09-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading function\n",
    "def data_load(table, name, start_time, end_time, timeformat):\n",
    "    \n",
    "    # Load data \n",
    "    df = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-rawdata.tql?table={table}&name={name}&start={start_time}&end={end_time}&timeformat={timeformat}')\n",
    "\n",
    "    # Convert to data grouped by the time\n",
    "    df = df.pivot_table(index='TIME', columns='NAME', values='VALUE', aggfunc='first').reset_index()\n",
    "\n",
    "    # Set TIME column\n",
    "    df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "\n",
    "    # Set time index\n",
    "    df.set_index('TIME', inplace=True)\n",
    "    \n",
    "    # Move the machine_status column to the end and rename it to label\n",
    "    df['machine_status'] = df.pop('machine_status')\n",
    "    df.rename(columns={'machine_status': 'label'}, inplace=True)\n",
    "    \n",
    "    # Convert label column data to integer type\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NAME</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_41</th>\n",
       "      <th>sensor_42</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.375000</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>37.22740</td>\n",
       "      <td>47.52422</td>\n",
       "      <td>31.11716</td>\n",
       "      <td>1.681353</td>\n",
       "      <td>419.5747</td>\n",
       "      <td>...</td>\n",
       "      <td>30.989580</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:01:00</th>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.375000</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>37.22740</td>\n",
       "      <td>47.52422</td>\n",
       "      <td>31.11716</td>\n",
       "      <td>1.681353</td>\n",
       "      <td>419.5747</td>\n",
       "      <td>...</td>\n",
       "      <td>30.989580</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:02:00</th>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.888900</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>37.86777</td>\n",
       "      <td>48.17723</td>\n",
       "      <td>32.08894</td>\n",
       "      <td>1.708474</td>\n",
       "      <td>420.8480</td>\n",
       "      <td>...</td>\n",
       "      <td>30.468750</td>\n",
       "      <td>31.770830</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:03:00</th>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.168400</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.125000</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>38.57977</td>\n",
       "      <td>48.65607</td>\n",
       "      <td>31.67221</td>\n",
       "      <td>1.579427</td>\n",
       "      <td>420.7494</td>\n",
       "      <td>...</td>\n",
       "      <td>30.468750</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:04:00</th>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.458300</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>39.48939</td>\n",
       "      <td>49.06298</td>\n",
       "      <td>31.95202</td>\n",
       "      <td>1.683831</td>\n",
       "      <td>419.8926</td>\n",
       "      <td>...</td>\n",
       "      <td>30.989580</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:55:00</th>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520830</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>634.722229</td>\n",
       "      <td>64.59095</td>\n",
       "      <td>43.17085</td>\n",
       "      <td>54.16052</td>\n",
       "      <td>38.05424</td>\n",
       "      <td>13.265320</td>\n",
       "      <td>420.7993</td>\n",
       "      <td>...</td>\n",
       "      <td>30.468750</td>\n",
       "      <td>30.208330</td>\n",
       "      <td>38.28125</td>\n",
       "      <td>68.287030</td>\n",
       "      <td>52.37268</td>\n",
       "      <td>48.32176</td>\n",
       "      <td>41.087960</td>\n",
       "      <td>212.3843</td>\n",
       "      <td>153.64580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:56:00</th>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.564240</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>630.902771</td>\n",
       "      <td>65.83363</td>\n",
       "      <td>43.21038</td>\n",
       "      <td>54.52602</td>\n",
       "      <td>38.53485</td>\n",
       "      <td>13.242270</td>\n",
       "      <td>422.1567</td>\n",
       "      <td>...</td>\n",
       "      <td>30.208332</td>\n",
       "      <td>29.947920</td>\n",
       "      <td>38.28125</td>\n",
       "      <td>66.840280</td>\n",
       "      <td>50.63657</td>\n",
       "      <td>48.03241</td>\n",
       "      <td>40.798610</td>\n",
       "      <td>213.8310</td>\n",
       "      <td>156.25000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:57:00</th>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520830</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>625.925903</td>\n",
       "      <td>67.29445</td>\n",
       "      <td>43.12836</td>\n",
       "      <td>55.11779</td>\n",
       "      <td>38.52678</td>\n",
       "      <td>13.188660</td>\n",
       "      <td>420.2166</td>\n",
       "      <td>...</td>\n",
       "      <td>29.947920</td>\n",
       "      <td>30.208330</td>\n",
       "      <td>39.06250</td>\n",
       "      <td>65.393520</td>\n",
       "      <td>48.90046</td>\n",
       "      <td>48.03241</td>\n",
       "      <td>40.798610</td>\n",
       "      <td>217.3032</td>\n",
       "      <td>155.38190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:58:00</th>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520832</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>635.648100</td>\n",
       "      <td>65.09175</td>\n",
       "      <td>42.35746</td>\n",
       "      <td>55.99321</td>\n",
       "      <td>38.89159</td>\n",
       "      <td>13.173460</td>\n",
       "      <td>420.5700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.947916</td>\n",
       "      <td>30.208332</td>\n",
       "      <td>40.62500</td>\n",
       "      <td>64.236110</td>\n",
       "      <td>47.74306</td>\n",
       "      <td>48.32176</td>\n",
       "      <td>40.509258</td>\n",
       "      <td>222.5116</td>\n",
       "      <td>153.93520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:59:00</th>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520832</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>639.814800</td>\n",
       "      <td>65.45634</td>\n",
       "      <td>42.62814</td>\n",
       "      <td>56.49642</td>\n",
       "      <td>39.40957</td>\n",
       "      <td>13.125930</td>\n",
       "      <td>421.2080</td>\n",
       "      <td>...</td>\n",
       "      <td>29.947916</td>\n",
       "      <td>30.208332</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>62.789350</td>\n",
       "      <td>46.29630</td>\n",
       "      <td>48.90046</td>\n",
       "      <td>40.219910</td>\n",
       "      <td>227.4306</td>\n",
       "      <td>150.46300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220320 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NAME                 sensor_01  sensor_02  sensor_03   sensor_04  sensor_05  \\\n",
       "TIME                                                                          \n",
       "2018-04-01 00:00:00   47.09201  53.211800  46.310760  634.375000   76.45975   \n",
       "2018-04-01 00:01:00   47.09201  53.211800  46.310760  634.375000   76.45975   \n",
       "2018-04-01 00:02:00   47.35243  53.211800  46.397570  638.888900   73.54598   \n",
       "2018-04-01 00:03:00   47.09201  53.168400  46.397568  628.125000   76.98898   \n",
       "2018-04-01 00:04:00   47.13541  53.211800  46.397568  636.458300   76.58897   \n",
       "...                        ...        ...        ...         ...        ...   \n",
       "2018-08-31 23:55:00   47.69965  50.520830  43.142361  634.722229   64.59095   \n",
       "2018-08-31 23:56:00   47.69965  50.564240  43.142361  630.902771   65.83363   \n",
       "2018-08-31 23:57:00   47.69965  50.520830  43.142361  625.925903   67.29445   \n",
       "2018-08-31 23:58:00   47.69965  50.520832  43.142361  635.648100   65.09175   \n",
       "2018-08-31 23:59:00   47.69965  50.520832  43.142361  639.814800   65.45634   \n",
       "\n",
       "NAME                 sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  \\\n",
       "TIME                                                                         \n",
       "2018-04-01 00:00:00   37.22740   47.52422   31.11716   1.681353   419.5747   \n",
       "2018-04-01 00:01:00   37.22740   47.52422   31.11716   1.681353   419.5747   \n",
       "2018-04-01 00:02:00   37.86777   48.17723   32.08894   1.708474   420.8480   \n",
       "2018-04-01 00:03:00   38.57977   48.65607   31.67221   1.579427   420.7494   \n",
       "2018-04-01 00:04:00   39.48939   49.06298   31.95202   1.683831   419.8926   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2018-08-31 23:55:00   43.17085   54.16052   38.05424  13.265320   420.7993   \n",
       "2018-08-31 23:56:00   43.21038   54.52602   38.53485  13.242270   422.1567   \n",
       "2018-08-31 23:57:00   43.12836   55.11779   38.52678  13.188660   420.2166   \n",
       "2018-08-31 23:58:00   42.35746   55.99321   38.89159  13.173460   420.5700   \n",
       "2018-08-31 23:59:00   42.62814   56.49642   39.40957  13.125930   421.2080   \n",
       "\n",
       "NAME                 ...  sensor_41  sensor_42  sensor_43  sensor_44  \\\n",
       "TIME                 ...                                               \n",
       "2018-04-01 00:00:00  ...  30.989580  31.770832   41.92708  39.641200   \n",
       "2018-04-01 00:01:00  ...  30.989580  31.770832   41.92708  39.641200   \n",
       "2018-04-01 00:02:00  ...  30.468750  31.770830   41.66666  39.351852   \n",
       "2018-04-01 00:03:00  ...  30.468750  31.510420   40.88541  39.062500   \n",
       "2018-04-01 00:04:00  ...  30.989580  31.510420   41.40625  38.773150   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "2018-08-31 23:55:00  ...  30.468750  30.208330   38.28125  68.287030   \n",
       "2018-08-31 23:56:00  ...  30.208332  29.947920   38.28125  66.840280   \n",
       "2018-08-31 23:57:00  ...  29.947920  30.208330   39.06250  65.393520   \n",
       "2018-08-31 23:58:00  ...  29.947916  30.208332   40.62500  64.236110   \n",
       "2018-08-31 23:59:00  ...  29.947916  30.208332   41.40625  62.789350   \n",
       "\n",
       "NAME                 sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  \\\n",
       "TIME                                                                         \n",
       "2018-04-01 00:00:00   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "2018-04-01 00:01:00   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "2018-04-01 00:02:00   65.39352   51.21528  38.194443   155.9606   67.12963   \n",
       "2018-04-01 00:03:00   64.81481   51.21528  38.194440   155.9606   66.84028   \n",
       "2018-04-01 00:04:00   65.10416   51.79398  38.773150   158.2755   66.55093   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2018-08-31 23:55:00   52.37268   48.32176  41.087960   212.3843  153.64580   \n",
       "2018-08-31 23:56:00   50.63657   48.03241  40.798610   213.8310  156.25000   \n",
       "2018-08-31 23:57:00   48.90046   48.03241  40.798610   217.3032  155.38190   \n",
       "2018-08-31 23:58:00   47.74306   48.32176  40.509258   222.5116  153.93520   \n",
       "2018-08-31 23:59:00   46.29630   48.90046  40.219910   227.4306  150.46300   \n",
       "\n",
       "NAME                 label  \n",
       "TIME                        \n",
       "2018-04-01 00:00:00      0  \n",
       "2018-04-01 00:01:00      0  \n",
       "2018-04-01 00:02:00      0  \n",
       "2018-04-01 00:03:00      0  \n",
       "2018-04-01 00:04:00      0  \n",
       "...                    ...  \n",
       "2018-08-31 23:55:00      0  \n",
       "2018-08-31 23:56:00      0  \n",
       "2018-08-31 23:57:00      0  \n",
       "2018-08-31 23:58:00      0  \n",
       "2018-08-31 23:59:00      0  \n",
       "\n",
       "[220320 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = data_load(table, name, start_time, end_time, timeformat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    62040\n",
      "1     4056\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    59770\n",
      "1     1919\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    84026\n",
      "1     8509\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, test sets\n",
    "train, test = train_test_split(df, test_size=0.7, shuffle=False)\n",
    "valid, test = train_test_split(test, test_size=0.6, shuffle=False)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(train['label'].value_counts())\n",
    "print(valid['label'].value_counts())\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* 1 Min-Max Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Applying Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    62040\n",
      "1     4056\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    59770\n",
      "1     1919\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    84026\n",
      "1     8509\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Scaler Setup\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Scaler\n",
    "train_ = scaler.fit_transform(train.iloc[:,:-1].values)\n",
    "valid_ = scaler.transform(valid.iloc[:,:-1].values)\n",
    "test_ = scaler.transform(test.iloc[:,:-1].values)\n",
    "\n",
    "# Set DataFrames\n",
    "train_scaled = pd.DataFrame(train_)\n",
    "valid_scaled = pd.DataFrame(valid_)\n",
    "test_scaled = pd.DataFrame(test_)\n",
    "\n",
    "# Add labels\n",
    "train_scaled['label'] = train['label'].values\n",
    "valid_scaled['label'] = valid['label'].values\n",
    "test_scaled['label'] = test['label'].values\n",
    "\n",
    "print(train_scaled['label'].value_counts())\n",
    "print(valid_scaled['label'].value_counts())\n",
    "print(test_scaled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Loader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pump_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.freq_data = df.iloc[:,:-1]\n",
    "        self.label = df.iloc[:,-1:].squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.freq_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        input_time_data = self.freq_data.iloc[index,:]\n",
    "        input_time_data = torch.Tensor(input_time_data).expand(1, input_time_data.shape[0])\n",
    "        label = self.label[index]\n",
    "\n",
    "        return input_time_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up datasets  \n",
    "train_ = Pump_Dataset(train_scaled)\n",
    "valid_ = Pump_Dataset(valid_scaled)\n",
    "test_ = Pump_Dataset(test_scaled)\n",
    "\n",
    "# Set up data loaders\n",
    "train_dataloader = DataLoader(train_, batch_size=1024, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_, batch_size=1024, shuffle=False)\n",
    "test_dataloader = DataLoader(test_, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "* Using Linear_classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Linear_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_classifier(\n",
      "  (fc1): Linear(in_features=44, out_features=20, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model configuration parameters\n",
    "# Learning rate\n",
    "learning_rate = 0.01\n",
    "input_dim = 44  \n",
    "hidden_dim = 20 \n",
    "output_dim = 2  \n",
    "\n",
    "# Model configuration\n",
    "model = Linear_classifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Configure loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10251f1539294c3e91911ed9aa122d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.345174629738148, train acc: 92.3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\MACH-DE-28\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.3441005078194503, train acc: 93.8635\n",
      "\n",
      "train loss: 0.2440626430092965, train acc: 98.1103\n",
      "\n",
      "train loss: 0.18924513601734835, train acc: 99.1966\n",
      "\n",
      "train loss: 0.15569150837618664, train acc: 99.2481\n",
      "\n",
      "train loss: 0.13307975759512153, train acc: 99.2798\n",
      "\n",
      "train loss: 0.11680572741508503, train acc: 99.2950\n",
      "\n",
      "train loss: 0.10451599298107193, train acc: 99.3025\n",
      "\n",
      "train loss: 0.09488818320206942, train acc: 99.3131\n",
      "\n",
      "train loss: 0.08713086775053022, train acc: 99.3177\n",
      "\n",
      "train loss: 0.08073631828077782, train acc: 99.3237\n",
      "\n",
      "train loss: 0.0753668083899351, train acc: 99.3252\n",
      "\n",
      "train loss: 0.0707867928465382, train acc: 99.3646\n",
      "\n",
      "train loss: 0.06682989109707622, train acc: 99.3812\n",
      "\n",
      "train loss: 0.06337338743855916, train acc: 99.4916\n",
      "\n",
      "train loss: 0.060325075123413105, train acc: 99.5143\n",
      "\n",
      "train loss: 0.057614489998614904, train acc: 99.5189\n",
      "\n",
      "train loss: 0.05518665000191882, train acc: 99.5234\n",
      "\n",
      "train loss: 0.05299769046074663, train acc: 99.5295\n",
      "\n",
      "train loss: 0.05101220460083862, train acc: 99.5340\n",
      "\n",
      "train loss: 0.04920134586450718, train acc: 99.5461\n",
      "\n",
      "train loss: 0.0475417918762172, train acc: 99.5567\n",
      "\n",
      "train loss: 0.04601499045864076, train acc: 99.5597\n",
      "\n",
      "train loss: 0.04460696961035218, train acc: 99.5643\n",
      "\n",
      "train loss: 0.043310870936859105, train acc: 99.5597\n",
      "\n",
      "train loss: 0.04213539943911201, train acc: 99.5582\n",
      "\n",
      "train loss: 0.0411056058298736, train acc: 99.5234\n",
      "\n",
      "train loss: 0.04017927960341854, train acc: 99.5249\n",
      "\n",
      "train loss: 0.03918577450869, train acc: 99.5658\n",
      "\n",
      "train loss: 0.038634680832396934, train acc: 99.1739\n",
      "\n",
      "train loss: 0.037794223390592525, train acc: 99.5643\n",
      "\n",
      "train loss: 0.03696254118838813, train acc: 99.6308\n",
      "\n",
      "train loss: 0.03627054950844862, train acc: 99.4947\n",
      "\n",
      "train loss: 0.035540456158863455, train acc: 99.6036\n",
      "\n",
      "train loss: 0.03494551717033075, train acc: 99.4009\n",
      "\n",
      "train loss: 0.03438633355326895, train acc: 99.5355\n",
      "\n",
      "train loss: 0.0337222902022621, train acc: 99.6172\n",
      "\n",
      "train loss: 0.03333248506632141, train acc: 99.3207\n",
      "\n",
      "train loss: 0.03286307505586649, train acc: 99.5295\n",
      "\n",
      "train loss: 0.03236101184141358, train acc: 99.5416\n",
      "\n",
      "train loss: 0.0318387939816933, train acc: 99.5991\n",
      "\n",
      "train loss: 0.031335638409931074, train acc: 99.5915\n",
      "\n",
      "train loss: 0.030817703646294704, train acc: 99.6142\n",
      "\n",
      "train loss: 0.03035159267656989, train acc: 99.6914\n",
      "\n",
      "train loss: 0.029891442124338013, train acc: 99.7156\n",
      "\n",
      "train loss: 0.029429754398215296, train acc: 99.6505\n",
      "\n",
      "train loss: 0.029058591333576758, train acc: 99.4463\n",
      "\n",
      "train loss: 0.028897773660732748, train acc: 99.3101\n",
      "\n",
      "train loss: 0.028655575198656812, train acc: 99.4508\n",
      "\n",
      "train loss: 0.02867826709839943, train acc: 98.9984\n"
     ]
    }
   ],
   "source": [
    "# Initialize training loss\n",
    "train_loss = []\n",
    "# Initialize training accuracy\n",
    "train_acc = []\n",
    "# Initialize total step\n",
    "total_step = len(train_dataloader)\n",
    "# Set number of epochs\n",
    "epoch_in = trange(50, desc='training')\n",
    "# Initialize best F1 Score value\n",
    "best_f1= 0\n",
    "\n",
    "# Start model training\n",
    "for epoch in epoch_in:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "\n",
    "    preds_ = []\n",
    "    targets_ = []\n",
    "\n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = train_data[0].to(device).float()\n",
    "        labels = train_data[1].to(device).long().squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Input to the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs.squeeze(1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Set label predictions \n",
    "        _,pred = torch.max(outputs.squeeze(1), dim=1)\n",
    "        correct += torch.sum(pred==labels).item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss)}, train acc: {(100 * correct / total):.4f}')\n",
    "    \n",
    "    # Perform validation at the end of each epoch and save the model with the best performance\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for batch_idx, valid_data in enumerate(valid_dataloader):\n",
    "\n",
    "            inputs_v = valid_data[0].to(device).float()\n",
    "            labels_v = valid_data[1].to(device).long().squeeze() \n",
    "            \n",
    "            outputs_v = model(inputs_v)\n",
    "            \n",
    "            # Set label predictions\n",
    "            _,pred_v = torch.max(outputs_v.squeeze(1), dim=1)\n",
    "            target_v = labels_v.view_as(pred_v)\n",
    "            \n",
    "            preds_.append(pred_v)\n",
    "            targets_.append(target_v)\n",
    "            \n",
    "        # Combine predictions and labels collected from all batches\n",
    "        preds_ = torch.cat(preds_).detach().cpu().numpy()\n",
    "        targets_ = torch.cat(targets_).detach().cpu().numpy()\n",
    "        \n",
    "        f1score = f1_score(targets_, preds_,  average='macro')\n",
    "        if best_f1 < f1score:\n",
    "            best_f1 = f1score\n",
    "            # Save the best model \n",
    "            with open(\"./result/Pump_General.txt\", \"a\") as text_file:\n",
    "                print('epoch=====',epoch, file=text_file)\n",
    "                print(classification_report(targets_, preds_, digits=4), file=text_file)\n",
    "            torch.save(model, f'./result/Pump_General.pt') \n",
    "        epoch_in.set_postfix_str(f\"epoch = {epoch},  f1_score = {f1score}, best_f1 = {best_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model_ = torch.load(f'./result/Pump_General.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing\n",
    "preds_test = []\n",
    "target_test = []\n",
    "with torch.no_grad():\n",
    "    model_.eval()\n",
    "    for batch_idx, test_data in enumerate(test_dataloader):\n",
    "        inputs_t = test_data[0].to(device).float()\n",
    "        labels_t = test_data[1].to(device).long().squeeze() \n",
    "        \n",
    "        outputs_t = model_(inputs_t)\n",
    "        \n",
    "        _,pred_t = torch.max(outputs_t.squeeze(1), dim=1)\n",
    "        targets_t = labels_t.view_as(pred_t).to(device)\n",
    "\n",
    "        preds_test.append(pred_t)\n",
    "        target_test.append(targets_t)\n",
    "        \n",
    "    # Combine predictions and labels collected from all batches\n",
    "    preds_test = torch.cat(preds_test).detach().cpu().numpy()\n",
    "    target_test = torch.cat(target_test).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     84026\n",
      "           1       0.94      0.95      0.94      8509\n",
      "\n",
      "    accuracy                           0.99     92535\n",
      "   macro avg       0.97      0.97      0.97     92535\n",
      "weighted avg       0.99      0.99      0.99     92535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_test, preds_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
