{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## 사용 라이브러리 호출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## 모델 사용 라이브러리 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange\n",
    "import statistics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "## 모델 학습 결과 경로 설정 \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Cuda 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 랜덤 시드 설정\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 시드 설정 \n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 데이터 컬럼 선택\n",
    "\n",
    "* tag name 이 많은 경우 tag name을 지정하는 것에 있어서 변수 설정이 다소 유연해짐\n",
    "* tag name 은 순서대로 불러와짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag name 출력 함수 \n",
    "def show_column(URL):\n",
    "    \n",
    "    # Tag name 데이터 로드\n",
    "    df = pd.read_csv(URL)\n",
    "    \n",
    "    # List 형식으로 변환\n",
    "    df = df.values.reshape(-1)\n",
    "    \n",
    "    return df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tag name 출력 파라미터 설정\n",
    "table = 'home'\n",
    "\n",
    "NAME_URL = f'http://127.0.0.1:5654/db/tql/datahub/api/v1/get_tag_names.tql?table={table}'\n",
    "\n",
    "## tag name list 생성 \n",
    "name = show_column(NAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TAG-Barn [kW]',\n",
       " 'TAG-Dishwasher [kW]',\n",
       " 'TAG-Fridge [kW]',\n",
       " 'TAG-Furnace 1 [kW]',\n",
       " 'TAG-Furnace 2 [kW]',\n",
       " 'TAG-Garage door [kW]',\n",
       " 'TAG-Home office [kW]',\n",
       " 'TAG-House overall [kW]',\n",
       " 'TAG-Kitchen 12 [kW]',\n",
       " 'TAG-Kitchen 14 [kW]',\n",
       " 'TAG-Kitchen 38 [kW]',\n",
       " 'TAG-Living room [kW]',\n",
       " 'TAG-Microwave [kW]',\n",
       " 'TAG-Solar [kW]',\n",
       " 'TAG-Well [kW]',\n",
       " 'TAG-Wine cellar [kW]',\n",
       " 'TAG-apparentTemperature',\n",
       " 'TAG-dewPoint',\n",
       " 'TAG-gen [kW]',\n",
       " 'TAG-humidity',\n",
       " 'TAG-precipIntensity',\n",
       " 'TAG-precipProbability',\n",
       " 'TAG-pressure',\n",
       " 'TAG-temperature',\n",
       " 'TAG-use [kW]',\n",
       " 'TAG-visibility',\n",
       " 'TAG-windBearing',\n",
       " 'TAG-windSpeed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG Name format 변환 \n",
    "\n",
    "* 위의 과정에서 Smart home dataset의 모든 Tag Name 을 확인후 사용할 컬럼만 뽑아서 입력할 파라미터 형태로 변환\n",
    "\n",
    "* TAG-windBearing, TAG-windSpeed Tag Name 사용하여 예제 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TAG-windBearing','TAG-windSpeed'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 원하는 tag name 설정\n",
    "# 여기서 tag name 은 컬럼을 의미\n",
    "tags = name[-2:]\n",
    "\n",
    "# 리스트의 각 항목을 작은따옴표로 감싸고, 쉼표로 구분\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "\n",
    "# 사용 tag name 확인\n",
    "print(tags_)\n",
    "\n",
    "# 해당 값을 모델의 input shape로 설정 \n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Home Dataset 로드\n",
    "\n",
    "* 데이터 로드시 train, validation, test 데이터 셋을 각각 Load\n",
    "\n",
    "* 예제는 각 데이터 셋 당 1시간의 데이터를 사용하는 것으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 파라미터 설정\n",
    "\n",
    "# tag table 이름 설정\n",
    "table = 'home'\n",
    "# tag name 설정\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# 시간 포멧 설정 \n",
    "timeformat = 'Default'\n",
    "\n",
    "# Train , validation , test 데이터 셋 설정\n",
    "# 학습 데이터 시작 시간 설정\n",
    "start_time_train = '2016-01-01 14:00:00'\n",
    "# 학습 데이터  끝 시간 설정\n",
    "end_time_train = '2016-01-01 15:00:00'\n",
    "\n",
    "# 검증 데이터 시작 시간 설정\n",
    "start_time_val = '2016-01-01 15:00:00'\n",
    "# 검증 데이터 끝 시간 설정\n",
    "end_time_val = '2016-01-01 16:00:00'\n",
    "\n",
    "# 테스트 데이터 시작 시간 설정\n",
    "start_time_test = '2016-01-01 16:00:00'\n",
    "# 테스트 데이터 끝 시간 설정 \n",
    "end_time_test = '2016-01-01 17:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "# '1D': 일간 간격 (1일)\n",
    "# '1H': 시간 간격 (1시간)\n",
    "# '1T' 또는 'min': 분 간격 (1분)\n",
    "# '1S': 초 간격 (1초)\n",
    "def data_load(table, name, start_time, end_time, timeformat, resample_time):\n",
    "    \n",
    "    # URL 인코딩\n",
    "    start_time = quote(start_time)\n",
    "    end_time = quote(end_time)\n",
    "    \n",
    "    # 데이터 로드 \n",
    "    df = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-rawdata.tql?table={table}&name={name}&start={start_time}&end={end_time}&timeformat={timeformat}')\n",
    "    \n",
    "    # 같은 시간대 별 데이터로 전환\n",
    "    df = df.pivot_table(index='TIME', columns='NAME', values='VALUE', aggfunc='first').reset_index()\n",
    "    \n",
    "    # time index 설정\n",
    "    df = df.set_index(pd.to_datetime(df['TIME']))\n",
    "    df = df.drop(['TIME'], axis=1)\n",
    "    \n",
    "    # 1초간격 resampling\n",
    "    # 원하는 간격으로 수정 가능 일, 시, 분 등등 \n",
    "    df = df.resample(f'{resample_time}').mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로드\n",
    "train = data_load(table, name, start_time_train, end_time_train, timeformat, \"1s\")\n",
    "# 검증 데이터 로드\n",
    "valid = data_load(table, name, start_time_val, end_time_val, timeformat, \"1s\")\n",
    "# 학습 데이터 로드\n",
    "test = data_load(table, name, start_time_test, end_time_test, timeformat, \"1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 14:00:00            282.0           9.18\n",
      "2016-01-01 14:00:01            282.0           9.18\n",
      "2016-01-01 14:00:02            282.0           9.18\n",
      "2016-01-01 14:00:03            282.0           9.18\n",
      "2016-01-01 14:00:04            282.0           9.18\n",
      "...                              ...            ...\n",
      "2016-01-01 14:59:56            253.0          11.30\n",
      "2016-01-01 14:59:57            253.0          11.30\n",
      "2016-01-01 14:59:58            253.0          11.30\n",
      "2016-01-01 14:59:59            253.0          11.30\n",
      "2016-01-01 15:00:00            253.0          11.30\n",
      "\n",
      "[3601 rows x 2 columns]\n",
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 15:00:00            253.0          11.30\n",
      "2016-01-01 15:00:01            253.0          11.30\n",
      "2016-01-01 15:00:02            253.0          11.30\n",
      "2016-01-01 15:00:03            253.0          11.30\n",
      "2016-01-01 15:00:04            253.0          11.30\n",
      "...                              ...            ...\n",
      "2016-01-01 15:59:56            232.0           3.91\n",
      "2016-01-01 15:59:57            232.0           3.91\n",
      "2016-01-01 15:59:58            232.0           3.91\n",
      "2016-01-01 15:59:59            232.0           3.91\n",
      "2016-01-01 16:00:00            232.0           3.91\n",
      "\n",
      "[3601 rows x 2 columns]\n",
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 16:00:00            232.0           3.91\n",
      "2016-01-01 16:00:01            232.0           3.91\n",
      "2016-01-01 16:00:02            232.0           3.91\n",
      "2016-01-01 16:00:03            232.0           3.91\n",
      "2016-01-01 16:00:04            232.0           3.91\n",
      "...                              ...            ...\n",
      "2016-01-01 16:59:56             43.0           4.83\n",
      "2016-01-01 16:59:57             43.0           4.83\n",
      "2016-01-01 16:59:58             43.0           4.83\n",
      "2016-01-01 16:59:59             43.0           4.83\n",
      "2016-01-01 17:00:00             43.0           4.83\n",
      "\n",
      "[3601 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(valid)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "* 각 데이터별로 MinMax Scaling 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 설정\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 스케일러 적용\n",
    "train_ = scaler.fit_transform(train.values)\n",
    "valid_ = scaler.transform(valid.values)\n",
    "test_ = scaler.transform(test.values)\n",
    "\n",
    "# 데이터 프레임 설정\n",
    "train_scaled = pd.DataFrame(train_ , columns=train.columns)\n",
    "valid_scaled = pd.DataFrame(valid_ , columns=valid.columns)\n",
    "test_scaled = pd.DataFrame(test_ , columns=test.columns)\n",
    "\n",
    "# 타임 인덱스 재설정\n",
    "train_scaled.index = train.index\n",
    "valid_scaled.index = valid.index\n",
    "test_scaled.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 14:00:00         0.966667       0.563459\n",
      "2016-01-01 14:00:01         0.966667       0.563459\n",
      "2016-01-01 14:00:02         0.966667       0.563459\n",
      "2016-01-01 14:00:03         0.966667       0.563459\n",
      "2016-01-01 14:00:04         0.966667       0.563459\n",
      "...                              ...            ...\n",
      "2016-01-01 14:59:56         0.644444       0.859135\n",
      "2016-01-01 14:59:57         0.644444       0.859135\n",
      "2016-01-01 14:59:58         0.644444       0.859135\n",
      "2016-01-01 14:59:59         0.644444       0.859135\n",
      "2016-01-01 15:00:00         0.644444       0.859135\n",
      "\n",
      "[3601 rows x 2 columns]\n",
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 15:00:00         0.644444       0.859135\n",
      "2016-01-01 15:00:01         0.644444       0.859135\n",
      "2016-01-01 15:00:02         0.644444       0.859135\n",
      "2016-01-01 15:00:03         0.644444       0.859135\n",
      "2016-01-01 15:00:04         0.644444       0.859135\n",
      "...                              ...            ...\n",
      "2016-01-01 15:59:56         0.411111      -0.171548\n",
      "2016-01-01 15:59:57         0.411111      -0.171548\n",
      "2016-01-01 15:59:58         0.411111      -0.171548\n",
      "2016-01-01 15:59:59         0.411111      -0.171548\n",
      "2016-01-01 16:00:00         0.411111      -0.171548\n",
      "\n",
      "[3601 rows x 2 columns]\n",
      "NAME                 TAG-windBearing  TAG-windSpeed\n",
      "TIME                                               \n",
      "2016-01-01 16:00:00         0.411111      -0.171548\n",
      "2016-01-01 16:00:01         0.411111      -0.171548\n",
      "2016-01-01 16:00:02         0.411111      -0.171548\n",
      "2016-01-01 16:00:03         0.411111      -0.171548\n",
      "2016-01-01 16:00:04         0.411111      -0.171548\n",
      "...                              ...            ...\n",
      "2016-01-01 16:59:56        -1.688889      -0.043236\n",
      "2016-01-01 16:59:57        -1.688889      -0.043236\n",
      "2016-01-01 16:59:58        -1.688889      -0.043236\n",
      "2016-01-01 16:59:59        -1.688889      -0.043236\n",
      "2016-01-01 17:00:00        -1.688889      -0.043236\n",
      "\n",
      "[3601 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled)\n",
    "print(valid_scaled)\n",
    "print(test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 윈도우 데이터 셋 설정\n",
    "\n",
    "시계열 데이터 학습을 위해서는 윈도우 사이즈와 슬라이딩 값을 설정해야함\n",
    "\n",
    "* window size : 몇개의 시간으로 묶을지에 대한 설정\n",
    "* step size : window 가 이동하는 시간 간격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 데이터셋 설정 \n",
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, data, window_size, step_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.windows = self._create_windows()\n",
    "    \n",
    "    # 슬라이딩 윈도우 설정 \n",
    "    def _create_windows(self):\n",
    "        windows = []\n",
    "        for i in range(0, len(self.data) - self.window_size + 1, self.step_size):\n",
    "            window = self.data[i:i + self.window_size]\n",
    "            windows.append(torch.Tensor(window.values))\n",
    "        return windows\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 설정\n",
    "window_size = 3\n",
    "step_size = 1 \n",
    "\n",
    "# 데이터 셋 설정 \n",
    "train_ = SlidingWindowDataset(train_scaled, window_size, step_size)\n",
    "valid_ = SlidingWindowDataset(valid_scaled, window_size, step_size)\n",
    "test_ = SlidingWindowDataset(test_scaled, window_size, step_size)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_dataloader = DataLoader(train_, batch_size=32, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(list(train_dataloader)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 \n",
    "\n",
    "* LSTM AE 기본 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder 클래스 정의\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        \n",
    "        # 인코더 LSTM\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.encoder_fc = nn.Linear(hidden_dim, 2*hidden_dim)\n",
    "        \n",
    "        # 디코더 LSTM\n",
    "        self.decoder_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더 부분\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        latent = self.encoder_fc(h[-1])\n",
    "        \n",
    "        # 디코더 부분\n",
    "        hidden = self.decoder_fc(latent).unsqueeze(0).repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        output, _ = self.decoder_lstm(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMAutoencoder(\n",
      "  (encoder_lstm): LSTM(2, 4, num_layers=3, batch_first=True)\n",
      "  (encoder_fc): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (decoder_fc): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (decoder_lstm): LSTM(4, 2, num_layers=3, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 파라미터\n",
    "\n",
    "# 입력 데이터 컬럼 수\n",
    "# Tag Name 수와 동일 \n",
    "input_dim = len(tags)\n",
    "\n",
    "# LSMT hidden state 크기\n",
    "hidden_dim = 2*len(tags)\n",
    "\n",
    "# layer 수\n",
    "num_layers = 3\n",
    "\n",
    "# 학습률 \n",
    "learning_rate = 0.01\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMAutoencoder(input_dim, hidden_dim, num_layers).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 설정\n",
    "\n",
    "* 학습 중 Loss 값이 제일 낮은 모델을 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9939cfd8dd4343a55ab7236d87933b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.11583049455245512\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.09801602310426863\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.09103955404907134\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.08712847792261189\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.08458687174916926\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.08279100409605894\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.08144886465213354\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.08040474738489911\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0795677098365008\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0788807465470256\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0783061602357805\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07781798646656198\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07739774099236686\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0770318977666934\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07671032088512011\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07642526288923243\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07617069679367676\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0759418656626687\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07573496423397971\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07554691351014725\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07537519451296698\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07521772793324083\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07507277853541841\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07493888688159374\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07481481213798434\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07469949221051944\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07459200906895574\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07449156656935925\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07439746848122253\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0743091057570154\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07422594154843024\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07414750233417494\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07407336755770343\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07400316357796717\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07393655655879114\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07387324669768676\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07381296497844275\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07375546811973463\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07370053640329445\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07364797049855702\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07359758937954919\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07354922869775107\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0735027378857792\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07345798050992981\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07341483156849246\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07337317663469221\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07333291154029083\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07329394052846179\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07325617606113385\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07321953827544089\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07318395363850834\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0731493547940205\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07311568017303352\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07308287279996611\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07305088080741143\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07301965658724037\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07298915570251112\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07295933793290234\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07293016588779423\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07290160493021365\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07287362361692022\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07284619204524259\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07281928348610035\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07279287235423024\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07276715970808328\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07274169698868636\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07271661224630233\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07269195372080343\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07266769624619851\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0726438203164407\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07262030953753132\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07259714903026114\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07257432479000742\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07255182429512783\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07252963552568767\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07250774719267189\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0724861487069261\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07246483008992799\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07244378177319898\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07242299501010963\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07240246128307222\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0723821724935467\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07236212123266969\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07234230024354844\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07232270259389537\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07230332188279871\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07228415188283288\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07226518694610755\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07224642139266552\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07222784993319105\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07220946747120781\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07219126933240551\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0721732506380211\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07215540732295517\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07213773516482408\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07212023002634006\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07210288830657068\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07208570634142085\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.07206868072374692\n",
      "모델 저장\n",
      "\n",
      "train loss: 0.0720518081592431\n",
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "total_step = len(train_dataloader)\n",
    "epoch_in = trange(100, desc='training')\n",
    "best_Loss= np.inf\n",
    "\n",
    "for epoch in epoch_in:\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    preds_ = []\n",
    "    targets_ = []\n",
    "\n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = train_data.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss)}')\n",
    "\n",
    "    \n",
    "    if best_Loss > np.mean(train_loss):\n",
    "        best_Loss = np.mean(train_loss)\n",
    "        torch.save(model, f'./result/Smart_home_LSTM_AE.pt')\n",
    "        print('모델 저장')\n",
    "    epoch_in.set_postfix_str(f\"epoch = {epoch}, best_Loss = {best_Loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임계값 설정\n",
    "\n",
    "* validation data를 사용하여 임계값 계산 \n",
    "1) 평균 + 편차 \n",
    "2) Max 값\n",
    "3) 99% - std 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델 로드\n",
    "model_ = torch.load(f'./result/Smart_home_LSTM_AE.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19576008091809938\n",
      "0.33034461736679077\n",
      "0.20584060850341562\n"
     ]
    }
   ],
   "source": [
    "# validation data 재구성 Loss 계산 \n",
    "valid_loss = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, valid_data in enumerate(valid_dataloader):\n",
    "\n",
    "        inputs_val = valid_data.to(device).float()\n",
    "\n",
    "        outputs_val = model_(inputs_val)\n",
    "        loss = criterion(outputs_val, inputs_val)\n",
    "        \n",
    "        valid_loss.append(loss.item())\n",
    "        \n",
    "# 임계값 설정\n",
    "threshold_1 =  statistics.mean(valid_loss) + statistics.stdev(valid_loss)\n",
    "threshold_2 =  max(valid_loss)\n",
    "threshold_3 =  np.percentile(valid_loss, 99) - statistics.stdev(valid_loss) \n",
    "\n",
    "print(threshold_1)\n",
    "print(threshold_2)\n",
    "print(threshold_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트\n",
    "\n",
    "* 이전 단계에서 계산한 임계값을 기준으로 테스트 데이터를 통한 모델 테스트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 모델 적용 \n",
    "test_loss = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, test_data in enumerate(test_dataloader):\n",
    "\n",
    "        inputs_test = test_data.to(device).float()\n",
    "\n",
    "        outputs_test = model_(inputs_test)\n",
    "        loss = criterion(outputs_test, inputs_test)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "\n",
    "# 테스트 결과 데이터 프레임 생성\n",
    "result = pd.DataFrame(test_loss, columns=['Reconst_Loss'])\n",
    "# 비정상 데이터는 없다고 가정 \n",
    "result['label'] = 0\n",
    "\n",
    "# 각 임계값 기준 정상, 비정상 구분\n",
    "result['pred_1'] = np.where(result['Reconst_Loss']>threshold_1,1,0)\n",
    "result['pred_2'] = np.where(result['Reconst_Loss']>threshold_2,1,0)\n",
    "result['pred_3'] = np.where(result['Reconst_Loss']>threshold_3,1,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 평가\n",
    "\n",
    "* F1 Score 기준으로 평가 진행 \n",
    "* 임계값 별로 성능 평가 진행 후 가장 좋은 성능을 보인 임계값을 fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91       113\n",
      "\n",
      "   micro avg       1.00      0.84      0.91       113\n",
      "   macro avg       1.00      0.84      0.91       113\n",
      "weighted avg       1.00      0.84      0.91       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 평균 + 편차 임계값 설정 \n",
    "print(classification_report(result['label'], result['pred_1'],labels=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           1.00       113\n",
      "   macro avg       1.00      1.00      1.00       113\n",
      "weighted avg       1.00      1.00      1.00       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Max 임계값 설정\n",
    "print(classification_report(result['label'], result['pred_2'],labels=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92       113\n",
      "\n",
      "   micro avg       1.00      0.86      0.92       113\n",
      "   macro avg       1.00      0.86      0.92       113\n",
      "weighted avg       1.00      0.86      0.92       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 99% - std 임계값 설정 \n",
    "print(classification_report(result['label'], result['pred_3'],labels=[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
