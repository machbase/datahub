{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## 사용 라이브러리 호출\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from urllib.parse import quote, unquote\n",
    "from datetime import timedelta\n",
    "\n",
    "## 모델 사용 라이브러리 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "## 모델 학습 사용 라이브러리\n",
    "from tqdm.notebook import trange\n",
    "import statistics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "## 모델 학습 결과 경로 설정 \n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "## Cuda 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "## 랜덤 시드 설정\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 시드 설정 \n",
    "seed_val = 77\n",
    "set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 데이터 컬럼 선택\n",
    "\n",
    "* tag name 이 많은 경우 tag name을 지정하는 것에 있어서 변수 설정이 다소 유연해짐\n",
    "* tag name 은 순서대로 불러와짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag name 출력 함수 \n",
    "def show_column(URL):\n",
    "    \n",
    "    # Tag name 데이터 로드\n",
    "    df = pd.read_csv(URL)\n",
    "    \n",
    "    # List 형식으로 변환\n",
    "    df = df.values.reshape(-1)\n",
    "    \n",
    "    return df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tag name 출력 파라미터 설정\n",
    "table = 'home'\n",
    "\n",
    "NAME_URL = f'http://127.0.0.1:5654/db/tql/datahub/api/v1/get_tag_names.tql?table={table}'\n",
    "\n",
    "## tag name list 생성 \n",
    "name = show_column(NAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TAG-Barn [kW]',\n",
       " 'TAG-Dishwasher [kW]',\n",
       " 'TAG-Fridge [kW]',\n",
       " 'TAG-Furnace 1 [kW]',\n",
       " 'TAG-Furnace 2 [kW]',\n",
       " 'TAG-Garage door [kW]',\n",
       " 'TAG-Home office [kW]',\n",
       " 'TAG-House overall [kW]',\n",
       " 'TAG-Kitchen 12 [kW]',\n",
       " 'TAG-Kitchen 14 [kW]',\n",
       " 'TAG-Kitchen 38 [kW]',\n",
       " 'TAG-Living room [kW]',\n",
       " 'TAG-Microwave [kW]',\n",
       " 'TAG-Solar [kW]',\n",
       " 'TAG-Well [kW]',\n",
       " 'TAG-Wine cellar [kW]',\n",
       " 'TAG-apparentTemperature',\n",
       " 'TAG-dewPoint',\n",
       " 'TAG-gen [kW]',\n",
       " 'TAG-humidity',\n",
       " 'TAG-precipIntensity',\n",
       " 'TAG-precipProbability',\n",
       " 'TAG-pressure',\n",
       " 'TAG-temperature',\n",
       " 'TAG-use [kW]',\n",
       " 'TAG-visibility',\n",
       " 'TAG-windBearing',\n",
       " 'TAG-windSpeed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG Name format 변환 \n",
    "\n",
    "* 위의 과정에서 Smart home dataset의 모든 Tag Name 을 확인후 사용할 컬럼만 뽑아서 입력할 파라미터 형태로 변환\n",
    "\n",
    "* TAG-windBearing, TAG-windSpeed Tag Name 사용하여 예제 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TAG-windBearing','TAG-windSpeed'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 원하는 tag name 설정\n",
    "# 여기서 tag name 은 컬럼을 의미\n",
    "tags = name[-2:]\n",
    "\n",
    "# 리스트의 각 항목을 작은따옴표로 감싸고, 쉼표로 구분\n",
    "tags_ = \",\".join(f\"'{tag}'\" for tag in tags)\n",
    "\n",
    "# 사용 tag name 확인\n",
    "print(tags_)\n",
    "\n",
    "# 해당 값을 모델의 input shape로 설정 \n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Home Dataset 로드\n",
    "\n",
    "* 데이터 로드는 필요할때 마다 필요한 만큼만 로드하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "# '1D': 일간 간격 (1일)\n",
    "# '1H': 시간 간격 (1시간)\n",
    "# '1T' 또는 'min': 분 간격 (1분)\n",
    "# '1S': 초 간격 (1초)\n",
    "def data_load(able, name, start_time_, end_time_, timeformat, resample_time):\n",
    "    \n",
    "    # 데이터 로드 \n",
    "    df = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-rawdata.tql?table={table}&name={name}&start={start_time_}&end={end_time_}&timeformat={timeformat}')\n",
    "    \n",
    "    # 같은 시간대 별 데이터로 전환\n",
    "    df = df.pivot_table(index='TIME', columns='NAME', values='VALUE', aggfunc='first').reset_index()\n",
    "    \n",
    "    # time index 설정\n",
    "    df = df.set_index(pd.to_datetime(df['TIME']))\n",
    "    df = df.drop(['TIME'], axis=1)\n",
    "    \n",
    "    # 1초간격 resampling\n",
    "    # 원하는 간격으로 수정 가능 일, 시, 분 등등 \n",
    "    df = df.resample(f'{resample_time}').mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 변환 함수\n",
    "# 시간 추가하려면 해당 과정 필요\n",
    "# window_size : 데이터를 묶어서 수집되는 주기 \n",
    "# step_size : 데이터의 간격 \n",
    "def add_time(start_time, batch_size, window_size, step_size):\n",
    "    \n",
    "    # 타임 스탬프 형식으로 변환 \n",
    "    start_time = pd.Timestamp(start_time)\n",
    "    \n",
    "    # 설정한 시간만큼의 시간을 추가\n",
    "    end_time_ = start_time + timedelta(seconds=(batch_size * step_size)+ window_size - step_size - 1)\n",
    "    next_start_time_ = end_time_ + timedelta(seconds= -abs(window_size - step_size - 1))\n",
    "    \n",
    "    # 다시 원래 형태로 출력\n",
    "    start_time_ = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_time_ = end_time_.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    next_start_time_ = next_start_time_.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # URL 인코딩\n",
    "    start_time_ = quote(start_time_)\n",
    "    end_time_ = quote(end_time_)\n",
    "    next_start_time_ = quote(next_start_time_)\n",
    "    \n",
    "    return start_time_, end_time_, next_start_time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택한 tag name 별 최대, 최소값 계산 함수\n",
    "def set_minmax_value(table, name, start_time_train, end_time_train):\n",
    "    \n",
    "    # URL 인코딩\n",
    "    start = quote(start_time_train)\n",
    "    end = quote(end_time_train)\n",
    "    \n",
    "    # min max 데이터 로드\n",
    "    df_ = pd.read_csv(f'http://127.0.0.1:5654/db/tql/datahub/api/v1/select-scale.tql?table={table}&name={name}&start={start}&end={end}')\n",
    "    \n",
    "    ## Min , Max values 설정 \n",
    "    Min = df_.iloc[:,1:-1].T\n",
    "    Max = df_.iloc[:,2:].T\n",
    "    \n",
    "    return Min, Max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window(data, window_size, step_size):\n",
    "    \n",
    "    # 윈도우 슬라이딩 결과를 저장할 리스트\n",
    "    windows = []\n",
    "\n",
    "    # 슬라이딩 윈도우 적용\n",
    "    for i in range(0, data.shape[0] - window_size + 1, step_size):\n",
    "        window = data[i:i + window_size, :]\n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaling 설정\n",
    "\n",
    "* Process 컨셉상 전체 데이터를 불러오지 않기 때문에 최대 최소값을 사용하는 방식의 Min-Max Sclare를 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler 클래스 정의\n",
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "\n",
    "    # 설정 파라미터 기반 scale 값 설정 \n",
    "    def transform(self, X, min_values, max_values):\n",
    "        X = np.array(X)\n",
    "        self.min_ = np.array(min_values)\n",
    "        self.max_ = np.array(max_values)\n",
    "        \n",
    "        if self.min_ is None or self.max_ is None:\n",
    "            raise ValueError(\"Min and Max values are not set.\")\n",
    "        \n",
    "        # scale 값이 0이되는 것을 막기 위해 1e-6 을 더해줌 \n",
    "        scale = (self.max_ - self.min_) + 1e-6\n",
    "        if np.any(scale == 0):\n",
    "            raise ValueError(\"Min and Max values are the same, resulting in a scale of 0.\")\n",
    "        \n",
    "        return (X - self.min_) / scale\n",
    "    \n",
    "    # 계산한 scale 값 기준 데이터 정규화 \n",
    "    def fit_transform(self, X, min_values, max_values):\n",
    "        \"\"\"Set parameters and then transform X\"\"\"\n",
    "        return self.transform(X,min_values, max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 \n",
    "\n",
    "* LSTM AE 기본 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder 클래스 정의\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        \n",
    "        # 인코더 LSTM\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.encoder_fc = nn.Linear(hidden_dim, 2*hidden_dim)\n",
    "        \n",
    "        # 디코더 LSTM\n",
    "        self.decoder_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 인코더 부분\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        latent = self.encoder_fc(h[-1])\n",
    "        \n",
    "        # 디코더 부분\n",
    "        hidden = self.decoder_fc(latent).unsqueeze(0).repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        output, _ = self.decoder_lstm(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMAutoencoder(\n",
      "  (encoder_lstm): LSTM(2, 4, num_layers=3, batch_first=True)\n",
      "  (encoder_fc): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (decoder_fc): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (decoder_lstm): LSTM(4, 2, num_layers=3, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 파라미터\n",
    "\n",
    "# 입력 데이터 컬럼 수\n",
    "# Tag Name 수와 동일 \n",
    "input_dim = len(tags)\n",
    "\n",
    "# LSMT hidden state 크기\n",
    "hidden_dim = 2*len(tags)\n",
    "\n",
    "# layer 수\n",
    "num_layers = 3\n",
    "\n",
    "# 학습률 \n",
    "learning_rate = 0.01\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMAutoencoder(input_dim, hidden_dim, num_layers).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "* 필요한 배치 크기의 데이터만 불러와서 학습하는 방법으로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수 설정\n",
    "def train(table, name, timeformat, model, start_time_train, end_time_train, batch_size, window_size, step_size, epochs):\n",
    "    \n",
    "    # 초기 train loss 설정\n",
    "    train_loss = []\n",
    "    \n",
    "    # 베스트 loss 초기화 \n",
    "    best_Loss=np.inf\n",
    "    \n",
    "    # 최대, 최소값 설정 \n",
    "    Min, Max = set_minmax_value(table, name, start_time_train, end_time_train)\n",
    "    \n",
    "    # Min-Max scaler 설정 \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        # 학습 모드 설정 \n",
    "        model.train()\n",
    "        \n",
    "        # 초기 loss 초기화\n",
    "        running_loss = 0.0\n",
    "        total_step = 0\n",
    "        \n",
    "        # 초기 시작 시간 설정\n",
    "        start_time_ = start_time_train\n",
    "\n",
    "        # while 문을 통해 데이터 호출 \n",
    "        while start_time_ < end_time_train:\n",
    "            \n",
    "            # 배치 크기에 따라 데이터 로드 \n",
    "            start_time_, end_time_, next_start_time_= add_time(start_time_, batch_size, window_size, step_size)\n",
    "            \n",
    "            # 데이터 로드 \n",
    "            data = data_load(table, name, start_time_, end_time_, timeformat, resample_time=\"1s\")\n",
    "             \n",
    "            # Min Max Scaling 적용\n",
    "            scaled_data = scaler.fit_transform(data, Min, Max)\n",
    "            \n",
    "            # window 설정 \n",
    "            windows = make_window(scaled_data, window_size, step_size)\n",
    "            \n",
    "            # 로드한 데이터가 비어 있을 경우 출력 \n",
    "            if len(scaled_data) == 0:\n",
    "                print(\"데이터가 없습니다.\")\n",
    "            \n",
    "            # 배치 사이즈 만큼 데이터가 쌓이면 다음 배치로 이동\n",
    "            if len(windows) == batch_size:\n",
    "                \n",
    "                # 총 배치수 체크용  \n",
    "                total_step = total_step + 1\n",
    "                \n",
    "                # 데이터를 numpy 배열로 변환\n",
    "                input_data = np.array(windows)\n",
    "\n",
    "                # 데이터를 Tensor로 변환\n",
    "                input_data = torch.tensor(input_data, dtype=torch.float32).to(device).float()\n",
    " \n",
    "                # 옵티마이저 최적화 \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 모델 입력\n",
    "                outputs = model(input_data)\n",
    "                \n",
    "                # loss 계산\n",
    "                loss = criterion(outputs, input_data)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # 배치 리셋\n",
    "                windows = []\n",
    "            \n",
    "            # 다음 시작 시간 설정    \n",
    "            start_time_ = unquote(next_start_time_)\n",
    "            \n",
    "        if total_step > 0:\n",
    "            train_loss.append(running_loss / total_step)\n",
    "            print(f'\\ntrain loss: {np.mean(train_loss)}')\n",
    "            \n",
    "        if best_Loss > np.mean(train_loss):\n",
    "            best_Loss = np.mean(train_loss)\n",
    "            torch.save(model, f'./result/Smart_home_LSTM_AE_New_Batch.pt')\n",
    "            print('베스트 모델 저장') \n",
    "            \n",
    "        epochs.set_postfix_str(f\"epoch = {epoch}, best_Loss = {best_Loss}\")\n",
    "               \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94108a8a41ca4f64a7388f9bf8483907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.12431900912022169\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.07182825464277273\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.05192385768898348\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.04170641856144679\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.035519949847006085\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.03137902159952187\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.028413706540860652\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.02618540141644447\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.024449429648893205\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.023058679470763056\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.02191939610247171\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.020968983457367085\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.020164045368483225\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01947354743091299\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01887470757924254\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01835042426312539\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.017887609563693067\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01747607563649425\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01710777228138994\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.016776251792308898\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01647628772628962\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.016203596700617967\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.015954634201971896\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.015726440789956993\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.015516526214639344\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.015322779667194995\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.015143400330949816\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014976842704928653\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.0148217730507009\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014677034362793969\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014541618395255607\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014414642630551089\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014295331392004746\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014183000270167272\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.014077043193917872\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013976921794565096\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013882156135526215\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013792317207990188\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013707020367989538\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013625919908221137\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013548704195502947\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013475091652090578\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013404827441025387\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013337680104325289\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013273439260648728\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013211913142809192\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013152926573336726\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01309631931754481\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.013041944516638225\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012989667299980365\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012939363580316119\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012890919041980349\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012844228193381659\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01279919350143783\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012755724680554746\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012713738016906034\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012673155828553238\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012633905826031636\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012595920787153228\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012559137968661555\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012523498861897055\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01248894878070204\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012455436513727441\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012422914147130306\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012391336763751077\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012360662113653088\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012330850589608757\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012301864874870578\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012273669838964833\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01224623236007476\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01221952123862846\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012193506928918288\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01216816157516615\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012143458783702932\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012119373619291315\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012095882388353737\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01207296266410533\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.012050593136806332\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01202875359291807\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01200742478515521\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011986588464527272\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01196622720961619\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011946324423830496\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011926864338313343\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011907831836931608\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011889212595110606\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011870992845361226\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011853159470825915\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.01183569994995658\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011818602266045485\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011801854941743153\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011785447005389365\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011769367895058103\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011753607544853141\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011738156248796323\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011723004748059429\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011708144103416498\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011693565765360774\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011679261510720653\n",
      "베스트 모델 저장\n",
      "\n",
      "train loss: 0.011665223426319735\n",
      "베스트 모델 저장\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMAutoencoder(\n",
       "  (encoder_lstm): LSTM(2, 4, num_layers=3, batch_first=True)\n",
       "  (encoder_fc): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (decoder_fc): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (decoder_lstm): LSTM(4, 2, num_layers=3, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 학습 파라미터 설정\n",
    "# tag table 이름 설정\n",
    "table = 'home'\n",
    "# tag name 설정\n",
    "name = quote(tags_, safe=\":/\")\n",
    "# 시작 시간 설정\n",
    "start_time_train = '2016-01-01 14:00:00'\n",
    "# 끝 시간 설정\n",
    "end_time_train = '2016-01-01 15:00:00'\n",
    "# 시간 포멧 설정 \n",
    "timeformat = 'Default'\n",
    "# 배치 사이즈 설정\n",
    "batch_size = 32\n",
    "# window size 설정\n",
    "window_size = 3\n",
    "# step size 설정 -> window size 보다 크거나 같으면 안됨 \n",
    "step_size = 1\n",
    "# epoch 설정\n",
    "epochs = trange(100, desc='training')\n",
    "\n",
    "# 학습 진행\n",
    "train(table, name, timeformat, model, start_time_train, end_time_train, batch_size, window_size, step_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임계값 설정\n",
    "\n",
    "* validation data를 사용하여 임계값 계산 \n",
    "1) 평균 + 편차 \n",
    "2) Max 값\n",
    "3) 99% - std 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_set(table, name, timeformat, model, start_time_train, end_time_train, start_time_val, end_time_val, batch_size, window_size, step_size, option):\n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # 초기 시작 시간 설정\n",
    "        start_time_ = start_time_val\n",
    "        \n",
    "        # 최대, 최소값 확인 \n",
    "        Min, Max = set_minmax_value(table, name, start_time_train, end_time_train)\n",
    "        \n",
    "        # Min-Max scaler 설정 \n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        # while 문을 통해 데이터 호출 \n",
    "        while start_time_ < end_time_val:\n",
    "            \n",
    "            # 윈도우 슬라이딩에 따라 데이터 \n",
    "            start_time_, end_time_, next_start_time_= add_time(start_time_, batch_size,window_size, step_size)\n",
    "            \n",
    "            # 데이터 로드 \n",
    "            data = data_load(table, name, start_time_, end_time_, timeformat, resample_time=\"1s\")\n",
    "            \n",
    "            # Min Max Scaling 적용\n",
    "            scaled_data = scaler.fit_transform(data, Min, Max)\n",
    "            \n",
    "            # window 설정 \n",
    "            windows = make_window(scaled_data, window_size, step_size)\n",
    "            \n",
    "            # 로드한 데이터가 비어 있을 경우 출력 \n",
    "            if len(scaled_data) == 0:\n",
    "                print(\"데이터가 없습니다.\")\n",
    "            \n",
    "            # 배치 사이즈 만큼 데이터가 쌓이면 다음 배치로 이동\n",
    "            if len(windows) == batch_size:\n",
    "                \n",
    "                # 데이터를 numpy 배열로 변환\n",
    "                input_data_val = np.array(windows)\n",
    "                \n",
    "                # 데이터를 Tensor로 변환\n",
    "                input_data_val = torch.tensor(input_data_val, dtype=torch.float32).to(device).float()\n",
    "\n",
    "                # 모델 입력\n",
    "                outputs_val = model(input_data_val)\n",
    "                \n",
    "                # loss 계산\n",
    "                loss_val = criterion(outputs_val, input_data_val)\n",
    "            \n",
    "                valid_loss.append(loss_val.item())\n",
    "                \n",
    "                # 배치 리셋\n",
    "                windows = []\n",
    "                \n",
    "            # 다음 시작 시간 설정    \n",
    "            start_time_ = unquote(next_start_time_)\n",
    "            \n",
    "        # 임계값 계산\n",
    "        if option == 0:\n",
    "            # 평균 + 편차값 \n",
    "            threshold =  statistics.mean(valid_loss) + statistics.stdev(valid_loss) \n",
    "            \n",
    "        # 임계값 계산\n",
    "        if option == 1:\n",
    "            # MAX 값 \n",
    "            threshold =  max(valid_loss)\n",
    "             \n",
    "        # 임계값 계산\n",
    "        if option == 2:\n",
    "            # 99% - std 값  \n",
    "            threshold =  np.percentile(valid_loss, 99) - statistics.stdev(valid_loss)             \n",
    "                    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 범위 설정 \n",
    "start_time_val = '2016-01-01 15:00:00'\n",
    "end_time_val = '2016-01-01 16:00:00'\n",
    "\n",
    "# 베스트 모델 로드\n",
    "model = torch.load(f'./result/Smart_home_LSTM_AE_New_Batch.pt')\n",
    "\n",
    "# 임계값 옵션 설정\n",
    "option = 2\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = threshold_set(table, name, timeformat, model, start_time_train, end_time_train, start_time_val, end_time_val, batch_size, window_size, step_size, option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트\n",
    "\n",
    "* 이전 단계에서 계산한 임계값을 기준으로 테스트 데이터를 통한 모델 테스트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트 함수 \n",
    "def test(table, name, timeformat, model, start_time_train, end_time_train, start_time_test, end_time_test, batch_size, window_size, step_size, threshold):\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # 초기 시작 시간 설정\n",
    "        start_time_ = start_time_test\n",
    "        \n",
    "        # 최대, 최소 값 설정 \n",
    "        Min, Max = set_minmax_value(table, name, start_time_train, end_time_train)\n",
    "\n",
    "        # Min-Max scaler 설정 \n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "        # while 문을 통해 데이터 호출 \n",
    "        while start_time_ < end_time_test:\n",
    "            \n",
    "            # 윈도우 슬라이딩에 따라 데이터 \n",
    "            start_time_, end_time_, next_start_time_= add_time(start_time_, batch_size, window_size, step_size)\n",
    "    \n",
    "            # 데이터 로드 \n",
    "            data = data_load(table, name, start_time_, end_time_, timeformat, resample_time=\"1s\")\n",
    "            \n",
    "            # Min Max Scaling 적용\n",
    "            scaled_data = scaler.fit_transform(data, Min, Max)\n",
    "            \n",
    "            # window 설정 \n",
    "            windows = make_window(scaled_data, window_size, step_size)\n",
    "            \n",
    "            # 로드한 데이터가 비어 있을 경우 출력 \n",
    "            if len(scaled_data) == 0:\n",
    "                print(\"데이터가 없습니다.\")\n",
    "            \n",
    "            # 배치 사이즈 만큼 데이터가 쌓이면 다음 배치로 이동\n",
    "            if len(windows) == batch_size:\n",
    "                \n",
    "                # 데이터를 numpy 배열로 변환\n",
    "                input_data_test = np.array(windows)\n",
    "                \n",
    "                # 데이터를 Tensor로 변환\n",
    "                input_data_test = torch.tensor(input_data_test, dtype=torch.float32).to(device).float()\n",
    "\n",
    "                # 모델 입력\n",
    "                outputs_test = model(input_data_test)\n",
    "                \n",
    "                # loss 계산\n",
    "                loss_test = criterion(outputs_test, input_data_test)\n",
    "            \n",
    "                test_loss.append(loss_test.item())\n",
    "                \n",
    "                # 배치 리셋\n",
    "                windows = []\n",
    "                \n",
    "            # 다음 시작 시간 설정    \n",
    "            start_time_ = unquote(next_start_time_) \n",
    "            \n",
    "    # 최종 결과 생성 \n",
    "    final_df = pd.DataFrame(test_loss, columns=['reconst_score'])\n",
    "    final_df['label'] = 0\n",
    "\n",
    "    # 각 임계값 별 label 설정 \n",
    "    final_df['pred_label'] = np.where(final_df['reconst_score']>threshold,1,0)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 범위 설정 \n",
    "start_time_test = '2016-01-01 16:00:00'\n",
    "end_time_test = '2016-01-01 17:00:00'\n",
    "\n",
    "result_df = test(table, name, timeformat, model, start_time_train, end_time_train, start_time_test, end_time_test, batch_size, window_size, step_size, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 평가\n",
    "\n",
    "* F1 Score 기준으로 평가 진행\n",
    "* 옵션별로 성능 평가 진행  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.12877620475788487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60       113\n",
      "\n",
      "   micro avg       1.00      0.43      0.60       113\n",
      "   macro avg       1.00      0.43      0.60       113\n",
      "weighted avg       1.00      0.43      0.60       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0. 평균 + 편차 임계값 설정\n",
    "print(f'임계값 {threshold}') \n",
    "print(classification_report(result_df['label'], result_df['pred_label'],labels=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.3305935859680176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       113\n",
      "\n",
      "   micro avg       1.00      0.99      1.00       113\n",
      "   macro avg       1.00      0.99      1.00       113\n",
      "weighted avg       1.00      0.99      1.00       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Max 값\n",
    "print(f'임계값 {threshold}') \n",
    "print(classification_report(result_df['label'], result_df['pred_label'],labels=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.20730006255657174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84       113\n",
      "\n",
      "   micro avg       1.00      0.73      0.84       113\n",
      "   macro avg       1.00      0.73      0.84       113\n",
      "weighted avg       1.00      0.73      0.84       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. 99% - std 값\n",
    "print(f'임계값 {threshold}') \n",
    "print(classification_report(result_df['label'], result_df['pred_label'],labels=[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
